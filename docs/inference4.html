<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUB-PsyR - The one-factorial ANOVA</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/QUBlogoWsmall.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">QUB-PsyR</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="./intro1.html">
 <span class="dropdown-text">R and RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro2.html">
 <span class="dropdown-text">Running Code in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro3.html">
 <span class="dropdown-text">Objects and Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro4.html">
 <span class="dropdown-text">Data Frames and Lists</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro5.html">
 <span class="dropdown-text">Saving and Loading Data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-working-with-r-objects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Working with R Objects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-working-with-r-objects">    
        <li>
    <a class="dropdown-item" href="./working1.html">
 <span class="dropdown-text">Binary Operators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working2.html">
 <span class="dropdown-text">Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working3.html">
 <span class="dropdown-text">Numerical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working4.html">
 <span class="dropdown-text">Logical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working5.html">
 <span class="dropdown-text">R Packages</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-inference" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Inference</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-statistical-inference">    
        <li>
    <a class="dropdown-item" href="./inference0.html">
 <span class="dropdown-text">A Primer on Statistical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference1.html">
 <span class="dropdown-text">The t-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference2.html">
 <span class="dropdown-text">The Chi²-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference3.html">
 <span class="dropdown-text">Correlations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference4.html">
 <span class="dropdown-text">One-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference5.html">
 <span class="dropdown-text">Two-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference6.html">
 <span class="dropdown-text">Repeated measures and mixed ANOVAs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference7.html">
 <span class="dropdown-text">Simple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference8.html">
 <span class="dropdown-text">Multiple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference9.html">
 <span class="dropdown-text">Multi-level models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The one-factorial ANOVA</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The Analysis of Variance (ANOVA) is a generalisation of the <span class="math inline">\(t\)</span>-Test. It is used to test the difference between two or more means against zero. When comparing groups using ANOVA, we partition the total variance inherent to the data (collapsed across all groups) into the variance between groups (i.e., the variance of the group means) and the variance within groups.</p>
<section id="the-foundations-of-anova" class="level2">
<h2 class="anchored" data-anchor-id="the-foundations-of-anova">The foundations of ANOVA</h2>
<p>A key concept in ANOVA is that of the <strong>sum of squares</strong>. To understand the sum of squares, let us consider the formal definition of the variance <span class="math inline">\(\sigma^2\)</span> of a variable, which looks as follows:</p>
<p><span class="math display">\[\sigma^2_x = \frac{1}{n} \times \underbrace{\Sigma{(x_i - \bar{x})^2}}_\text{sum of squares}\]</span></p>
<p>From this equation, we can see that the variance of the variable <span class="math inline">\(x\)</span> is the product of two components. One is the <strong>sum of squares</strong>, that is, the sum of the squared deviations of each observation <span class="math inline">\(x_i\)</span> from their mean <span class="math inline">\(\bar{x\)</span>}. The second factor simply divides this sum of squares by the number of observations <span class="math inline">\(n\)</span>.</p>
<p>When we estimate the true variance <span class="math inline">\(\sigma^2_x\)</span> from data we collected, using the formula above produces a slight bias. Specifically, our estimate of the true variance will be systematically too low. To arrive at an unbiased estimate, we need to divide the sum of squares by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>, leading to the following formal definition of the <strong>estimate of the variance</strong> <span class="math inline">\(\hat{\sigma}^2_x\)</span>:</p>
<p><span class="math display">\[\hat{\sigma}^2_x = \frac{1}{n-1}\Sigma{(x_i - \bar{x})^2}\]</span></p>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: Dividing a sum of squares by its degrees of freedom yields the so called <strong>mean squares</strong>. The mean squares follow a <span class="math inline">\(\chi^2\)</span>-distribution with the respective degrees of freedom.</p>
</div>
</section>
<section id="the-logic-of-the-anova" class="level2">
<h2 class="anchored" data-anchor-id="the-logic-of-the-anova">The logic of the ANOVA</h2>
<p>The whole idea of ANOVA rests on the fact that the variance can be partitioned into the sum of its parts. This is also true for the the <strong>sum of squares</strong>. As a very basic rule, we can state that:</p>
<p><span class="math display">\[SS_{total} = SS_{between} + SS_{within}\]</span></p>
<p>Here, <span class="math inline">\(SS_{total}\)</span> is a measure of the total variability of a variable, <span class="math inline">\(SS_{between}\)</span> represents that part of the total variability that is due to differences of the group means, and <span class="math inline">\(SS_{within}\)</span> represents the part of the total variability that results from heterogeneity within the groups.</p>
<p>Similar to the <span class="math inline">\(t\)</span>-test, ANOVA is a signal to noise ratio, where we treat variability between groups as the signal and variability within groups as the noise. The test statistic we use to test for significant mean differences between groups is the <span class="math inline">\(F\)</span>-value, which is formally defined as:</p>
<p><span class="math display">\[F = \frac{VAR_{between}}{VAR_{within}}=\frac{\frac{SS_{between}}{df_{between}}}{\frac{SS_{within}}{df_{within}}} = \frac{MS_{between}}{MS_{within}}\]</span></p>
<p>In the formula above, <span class="math inline">\(MS\)</span> is the corresponding <em>mean squares</em>.</p>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: Based on the formula above, we can easily derive that <span class="math inline">\(F\)</span> is the ratio of two <span class="math inline">\(\chi^2\)</span>-distributed variables. Both the numerator and the denominator constitute a sum of squares divided by its degrees of freedom. That is also the reason why the <span class="math inline">\(F\)</span>-distribution has two degrees of freedom, one for the numerator and one for the denominator.</p>
</div>
<p>How we compute the mean squares depends on the type of ANOVA we run and the number of groups we compare in it.</p>
<p>However, we can state generally how we compute the different <strong>sum of squares</strong>. First of all, let’s remember how we compute the total sum of squares, <span class="math inline">\(SS_{total}\)</span>:</p>
<p><span class="math display">\[SS_{total} = \sum_{i=1}^{N} (x_i - \bar{x})^2\]</span></p>
<p>The total sum of squares represent the sum of the squared deviation of all <span class="math inline">\(N\)</span> observed data points from the grand mean <span class="math inline">\(\bar{x}\)</span>. Now lets look at the formula for <span class="math inline">\(SS_{between}\)</span>.</p>
<p><span class="math display">\[SS_{between} = \sum_{j=1}^{J} n_j \times (\bar{x}_j - \bar{x})^2\]</span></p>
<p>Here, <span class="math inline">\(J\)</span> is the number of groups we compare, and <span class="math inline">\(n_j\)</span> is the sample size of group <span class="math inline">\(j\)</span>. For the <span class="math inline">\(SS_{between}\)</span> we pretend that there is no variance within the <span class="math inline">\(J\)</span> groups at all. Each observation is represented by its group’s mean <span class="math inline">\(\bar{x}_j\)</span>, and we compute the variability as the difference of these group means from the grand mean <span class="math inline">\(\bar{x}\)</span>. Therefore, the <span class="math inline">\(SS_{between}\)</span> isolates the between-group part of the total variability of <span class="math inline">\(x\)</span>. Let’s now turn to the <span class="math inline">\(SS_{within}\)</span>.</p>
<p><span class="math display">\[SS_{within} = \sum_{j=1}^{J} \sum_{i = 1}^{n_j} (x_{ij} - \bar{x}_j)\]</span></p>
<p>Again, <span class="math inline">\(J\)</span> is the number of groups we compare, and <span class="math inline">\(n_j\)</span> is the sample size in group <span class="math inline">\(j\)</span>. The <span class="math inline">\(x_{ij}\)</span> refers to the <span class="math inline">\(i\)</span>th observation in group <span class="math inline">\(j\)</span>. For the <span class="math inline">\(SS_{within}\)</span>, we pretend that there is no variance between groups at all. We do so by substituting the <em>grand mean</em> for the respective group means <span class="math inline">\(\bar{x}_j\)</span>. Thus, the <span class="math inline">\(SS_within\)</span> isolates the within-group variability of <span class="math inline">\(x\)</span>.</p>
<p>The final thing we need to understand before we can delve into the actual ANOVAs is the <span class="math inline">\(F\)</span>-statistic. As we have seen above, we compute <span class="math inline">\(F\)</span> as a ratio of the <span class="math inline">\(MS_{between}\)</span> and the <span class="math inline">\(MS_{within}\)</span>. This ratio is interesting in several ways:</p>
<ol type="1">
<li>Since the <span class="math inline">\(SS_{between}\)</span> usually has much fewer degrees of freedom than that <span class="math inline">\(SS_{within}\)</span>, the variability between groups does not have to be nearly as large as the variability within groups to produce a large <span class="math inline">\(F\)</span>-value.</li>
<li>The more groups we compare, the lower the <span class="math inline">\(F\)</span>-ratio will be, ceteris paribus. However, this does not necessarily mean that it becomes more difficult to detect significant mean differences. The more groups we compare, and the more numerator degrees of freedom our test has, the lower the critical <span class="math inline">\(F\)</span>-value past which we consider a result statistically significant.</li>
<li>The larger our total sample, the more denominator degrees of freedom we have, and smaller the noise becomes in our signal-to-noise ratio, ceteris paribus. This makes intuitive sense: as the samples size increases, our measurement becomes more precise, making it easier to detect differences between group means.</li>
</ol>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: If we use an ANOVA to compare two means, we effectively run a <span class="math inline">\(t\)</span>-test but discard its ability to indicate the direction of the effect.</p>
<p>In such cases <span class="math inline">\(F = t^2\)</span>, and the <span class="math inline">\(p\)</span>-value of both tests will be identical if we run a <span class="math inline">\(t\)</span>-test assuming equal variances.</p>
</div>
<p>ANOVAs come in various flavours. In the following, we will look at some of them, namely:</p>
<ul>
<li>one-factorial ANOVAs (between-subjects)</li>
<li>two-factorial ANOVAs (between-subjects)</li>
<li>repeated-measures ANOVAs (within-subjects)</li>
<li>mixed ANOVAs (at least one between and within factor)</li>
</ul>
</section>
<section id="one-factorial-anova" class="level2">
<h2 class="anchored" data-anchor-id="one-factorial-anova">One-factorial ANOVA</h2>
<p>In a one-factorial ANOVA, we compare two or more group means such that we consider each group to represent one level of the same grouping variable or factor <span class="math inline">\(A\)</span>. The underlying model assumes that the true mean of each of the <span class="math inline">\(j\)</span> groups <span class="math inline">\(\mu_j\)</span> is the sum of the true grand mean and the effect of the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span> on that mean. We call these effects <span class="math inline">\(\alpha_j\)</span>.</p>
<p><span class="math inline">\(\mu_j = \mu + \alpha_j\)</span></p>
<p>This is equivalent to:</p>
<p><span class="math inline">\(\alpha_j = \mu_j - \mu\)</span></p>
<p>In other words, the effect of the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span> is the difference between the true group mean <span class="math inline">\(\mu_j\)</span> and the true grand mean <span class="math inline">\(\mu\)</span>. Accordingly, if <span class="math inline">\(\mu_j\)</span> exceeds <span class="math inline">\(\mu\)</span>, the respective <span class="math inline">\(\alpha_j\)</span> is positive.</p>
<p>The Null hypothesis is that all group means are equal. This equivalent to stating that all <span class="math inline">\(\alpha_j\)</span> are zero. The alternative hypothesis is that not all group means are equal or, put differently, that at least oe of the <span class="math inline">\(\alpha_j\)</span> is non-zero.</p>
<p><span class="math inline">\(H0:\alpha_j = 0 \quad \forall j\)</span></p>
<p><span class="math inline">\(H1: \lnot H_0\)</span></p>
<p>Running ANOVAs in base R tends to be very clunky because R is more centered around classic regression models. Therefore, we won’t be using base R to run ANOVAs, but instead use an R package called <em>afex</em> (Analysis of Factorial Experiment). That means, we need to install and load <em>afex</em> first.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("afex")</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(afex)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>Once we have done that, we can start doing ANOVAs with one of several functions:</p>
<ul>
<li><em>aov_car</em></li>
<li><em>aov_4</em></li>
<li><em>aov_ez</em></li>
</ul>
<p>The three functions serve the same goal and do the same things, but they differ in terms of the syntax. The function <em>aov_car</em> uses syntax that is most closely related the the (clunky) base R version of ANOVA. In contrast, <em>aov_4</em> uses syntax based on the popular <em>lme4</em> package that is widely used for the analysis of generalised mixed models. Thus, this function is ideally suited for users who are already familiar with <em>lme4</em>. Finally, <em>aov_ez</em> uses a completely string-based format, that is, it does not require a formula type object as a function argument. The advantage of <em>aov_ez</em> is that it is very convenient and easy to handle (thus the suffix “ez”). This comes at the cost of flexibility. The lack of a formula means that we are stuck with a full ANOVA model. The other two functions technically allow us to specify models that omit certain main effects or interactions. However, since we will rarely want to run these incomplete models, this is a drawback that usually causes no hassles. In the following, we will focus on the <em>aov_ez</em> function and leave exploration of the other functions to the discretion of the reader.</p>
<p>Here are the most important function arguments of <em>aov_ez</em>:</p>
<ul>
<li><em>id</em> (necessary): a character value indicating the name of the variable that contains our subject ID</li>
<li><em>dv</em> (required): another character value; the name of the variable containing the data the group means of which we want to compare</li>
<li><em>data</em> (required): an R object of type data frame containing the data we want to analyse</li>
<li><em>between</em> (optional): a character string or character vector indicating the name(s) of the variable(s) constituting the between-subjects factor(s) of our design; default is NULL meaning that there are no between-subjects factors</li>
<li><em>within</em> (optional): a character string or character vector indicating the name(s) of the variable(s) constituting the within-subjects factor(s) of our design; default is NULL meaning that there are no within-subjects factors</li>
<li><em>covariate</em>: a character value or vector indicating the name(s) of the covariate(s) in our analysis</li>
<li><em>factorize</em> (optional): a logical value; determines if the between- and within-subject variables are turned into factors prior to the analysis; default is TRUE; if our design has at least one covariate, we need to set this to FALSE and make sure that all factors are defined as such manually</li>
<li><em>anova_table</em> (optional): a list of further arguments passed to the function; the ones we may be interested in are <em>es</em> (effect size; default is ‘ges’, which yields <span class="math inline">\(\eta^2\)</span> as an effect size measure, but we can switch it to ‘none’ or to ‘pes’, which yields <span class="math inline">\(\eta^2_p\)</span>) and <em>correction</em> (non-sphericity correction method; default is ‘none’, bu we can switch it to ‘GG’ for the Greenhouse-Geisser or ‘HF’ for the Huynh-Feldt correction)</li>
</ul>
<p>For the purpose of running a one-factorial between-subjects ANOVA, we can disregard some of the function arguments shown above. The only ones we need are <em>id</em>, <em>dv</em>, <em>between</em>, and possibly <em>anova_table</em> in case we want to obtain the effect size.</p>
<div class="alert alert-danger">
<p>Now that we want to do ANOVAs, it is time to talk about <strong>factors</strong>. In R, <strong>factors</strong> are a special type of vector that contain both values and labels for those values. The different values of vectors are considered to be categories. Factors are important because the ANOVA-function we use here requires its between- and within-subject variables to be factors.</p>
<p>We can create a factor using the <em>factor</em> function by feeding it the following function arguments:</p>
<ul>
<li><em>x</em>: a vector we want to turn into a factor</li>
<li><em>levels</em>: a vector containing all possible values the factor can take</li>
<li><em>labels</em>: a character vector assigning a label to each level of the factor</li>
</ul>
</div>
<p>Lets look at an example, in which we test whether the means of three groups are equal or not. First, we need to create some data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a data frame containing data from 30 subjects in three groups of 10 each; here, "id" is the subject identifier, "cond" is the between-subjects grouping variable, and "dv" contains the outcome variable we want to compare between groups</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># subject ID</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>,      </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># between-subjects-factor 'cond'</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cond =</span> <span class="fu">factor</span>(  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rep</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">each =</span> <span class="dv">10</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">'control'</span>, <span class="st">'treatment1'</span>, <span class="st">'treatment2'</span>)),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># outcome variable 'dv'</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">dv =</span> <span class="fu">c</span>(</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">12</span>,  <span class="dv">9</span>, <span class="dv">14</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">18</span>, <span class="dv">12</span>), <span class="co"># dv data for control</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>( <span class="dv">9</span>,  <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">14</span>,  <span class="dv">8</span>,  <span class="dv">7</span>, <span class="dv">16</span>, <span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">16</span>), <span class="co"># dv data for treatment1</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="dv">12</span>, <span class="dv">11</span>, <span class="dv">11</span>,  <span class="dv">9</span>,  <span class="dv">8</span>, <span class="dv">13</span>,  <span class="dv">8</span>,  <span class="dv">6</span>, <span class="dv">14</span>,  <span class="dv">7</span>)) <span class="co"># dv data for treatment2</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can inspect how the data frame looks using the <em>head</em> function.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID    cond dv
1  1 control 10
2  2 control 12
3  3 control  9
4  4 control 14
5  5 control 11
6  6 control 15</code></pre>
</div>
</div>
</div>
<p>Now that we have some data, we can run the ANOVA. The syntax looks as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">between =</span> <span class="st">'cond'</span>, <span class="at">dv =</span> <span class="st">'dv'</span>, <span class="at">data =</span> my_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what the output in the console looks like:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Contrasts set to contr.sum for the following variables: cond</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: dv
  Effect    df  MSE    F  ges p.value
1   cond 2, 27 9.27 2.44 .153    .106
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, R displays an ANOVA table in the console along with some additional information. The output is preceded by a message (this is NOT an error message; the code ran properly). This message informs us that the <em>aov_ez</em> function set the contrast type for our factor ‘cond’ to ‘contr.sum’. What this means is that the contrast underling our factor was forced into effect coding because that is the format that ANOVAs use. We don’t need to concern ourselves with that.</p>
<p>Next, R will tell us that this output is an ANOVA table based on type-3 sum of squares. Type-3 sums of squares are what most statistics packages use. If your knowledge of statistics is so advanced that you can make an informed decision that you would prefer type-2 sums of squares, you can change it by setting the <em>type</em> function argument to 2.</p>
<p>Now for the important bits. R shows us what the response variable in our model is, namely ‘dv’. Below that information, it displays the ANOVA table. Because we ran a one-factorial ANOVA; this table contains only one row. Here, we can see the name of the between-subjects factor (<em>effect</em>), the numerator and denominator degrees of freedom for its <span class="math inline">\(F\)</span>-value (<em>df</em>), the mean squares of the effect (<em>MSE</em>), the <span class="math inline">\(F\)</span>-value, the generalised <span class="math inline">\(\eta^2\)</span> as a measure of the effect size, and the <span class="math inline">\(p\)</span>-value.</p>
<p>In our example, the mean difference is not statistically significant, which mans that we cannot reject the null hypothesis. In other words, we cannot say whether the true means between the three groups differ.</p>
<div class="alert alert-info">
<p>Similar to the <span class="math inline">\(\chi^2\)</span>-test, the <span class="math inline">\(F\)</span>-test we use in an ANOVA is always a one-tailed test because it is based on squared variables. Therefore, the test has no ‘direction’ as a <span class="math inline">\(t\)</span>-test would.</p>
<p>Why is this important? Sometimes, we might encounter a scientific article, in which the authors state that they ran a ‘one-tailed’ ANOVA test, but what they do in those articles is simply the divide their <span class="math inline">\(p\)</span>-value by 2. This practice (often encountered when the regular <span class="math inline">\(p\)</span>-value lies between .05 and .10) rests on the erroneous belief that all statistical tests are - per default - two-tailed and can, therefore, also be run as a one-tailed test with slightly greater power.</p>
</div>
</section>
<section id="disentangling-significant-effects-in-anovas" class="level2">
<h2 class="anchored" data-anchor-id="disentangling-significant-effects-in-anovas">Disentangling significant effects in ANOVAs</h2>
<p>In the example above, we had to retain the Null hypothesis because the analysis did not show evidence that the three means were different from each other. In those cases, there is no need for further analyses. However, things look a bit different when the ANOVA yields a significant result. Let’s look at an example.</p>
<p>In this example, we will compare two treatments and one control condition with data for 30 participants in each condition. The data is stored in a data frame called <em>my_df2</em>. Here is what the data looks like (we use the function <em>head</em> on the data frame to have R show us the first 6 lines).</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID    cond  dv
1  1 control  88
2  2  treat1 119
3  3  treat2 119
4  4 control 103
5  5  treat1 103
6  6  treat2 137</code></pre>
</div>
</div>
</div>
<p>We now run the ANOVA on the data. Other than before, we will define the result of the analysis as a new R object. This will make it easier for us to disentangle the effect later on. Here is the syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run a one-factorial ANOVA and save its results as a new R object</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">dv =</span> <span class="st">'dv'</span>, <span class="at">between =</span> <span class="st">'cond'</span>, <span class="at">data =</span> my_df2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will now see a new object called “model1” in the <strong>Environment</strong>. R will tell us that this object is a list. Entering the new object’s name as syntax will show us the result of the ANOVA just as if we had called the function as is instead of defining it as a new object. Here is the console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: dv
  Effect    df   MSE         F  ges p.value
1   cond 2, 87 89.48 22.91 *** .345   &lt;.001
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, the effect of <em>cond</em> (the grouping variable in our fictional data) is statistically significant. We can now state - with the usual confidence - that the means of the three groups are not equal. However, we cannot say anything else. Since an ANOVA uses the squared test statistic <span class="math inline">\(F\)</span>, we have no information on the direction of the mean differences, nor do we know which means differ. Thus, we need further analyses to get a clear picture of the mean differences the ANOVA detected.</p>
<div class="alert alert-info">
<p>As a useful - if somewhat brutish - metaphor, think of an ANOVA as firing a shotgun into think fog. A statistically significant effect means that we hit something, but we do not know what we hit. In order to find that out we need to venture into the fog and have a closer look.</p>
<p>(Credit for this metaphor goes to Prof.&nbsp;Dieter Heyer)</p>
</div>
<p>In order to disentangle a significant effect in an ANOVA with three or more groups, we need to run <strong>post-hoc</strong> analyses. There are many different ways to run such post-hoc analyses. Here, we will focus on <strong>post-hoc contrasts</strong>.</p>
<section id="post-hoc-t-tests" class="level3">
<h3 class="anchored" data-anchor-id="post-hoc-t-tests">Post-hoc t-tests</h3>
<p>Before we delve into <strong>post-hoc</strong> contrasts, it is worth mentioning that one easy way to disentangle significant effects in an ANOVA is running <span class="math inline">\(t\)</span>-tests to compare the means of the groups. We already know how to do this, namely by using the <em>t.test</em> function.</p>
<p>However, there are three downsides to using simple <span class="math inline">\(t\)</span>-tests. First, they are less powerful than contrasts because their estimate of the error variance is based on only a part of the total sample. Second, if we want to control the type-I error rate by adjusting for multiple comparisons, we need to do so manually (this may be easy for Bonferroni’s method, but more challenging for less conservative adjustment methods). Third, as the number of groups we compare in an ANOVA increases, so does the number of possible pairwise comparisons. In fact, the number of comparisons is <span class="math inline">\((k^2-k)/2\)</span>, that is, it grows exponentially. Thereofre, the amount of code we need to write also increases accordingly.</p>
</section>
<section id="pairwise-comparisons-using-contrasts" class="level3">
<h3 class="anchored" data-anchor-id="pairwise-comparisons-using-contrasts">Pairwise comparisons using contrasts</h3>
<p>An alternative to running individual <span class="math inline">\(t\)</span>-tests is to do pairwise comparisons using post-hoc contrasts. A contrast is a weighted average of the group means <span class="math inline">\(\bar{x}_j\)</span> of the <span class="math inline">\(J\)</span> groups we compare.</p>
<p><span class="math display">\[\hat{\psi} = \sum_{j=1}^{J} c_j \bar{x}_j\]</span></p>
<p>It must satisfy the condition that the weights <span class="math inline">\(c_j\)</span> add to zero:</p>
<p><span class="math display">\[\sum_{j=1}^{J} c_j = 0\]</span></p>
<p>The standard error of a contrast <span class="math inline">\(\hat{\psi}\)</span> is computed based on <strong>all data</strong>. That is why contrasts are usually more powerful than run-og-the-mill <span class="math inline">\(t\)</span>-tests. The standard error is defined as:</p>
<p><span class="math display">\[S_{\hat{\psi}} = \sqrt{MS_{within} \sum_{j=1}^{J} \frac{c_j^2}{n_j}}\]</span></p>
<p>Dividing a contrast <span class="math inline">\(\hat{\psi}\)</span> by its standard error <span class="math inline">\(S_{\hat{\psi}}\)</span> yields a variable that follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(N-J\)</span> degrees of freedom, where <span class="math inline">\(N\)</span> is the total sample size, and <span class="math inline">\(J\)</span> is the umber of groups.</p>
<p><span class="math display">\[\frac{\hat{\psi}}{S_{\hat{\psi}}} \sim t_{N-J}\]</span> Testing a contrast comes down to running a one-sample <span class="math inline">\(t\)</span>-test to test (for example):</p>
<p><span class="math inline">\(H_0: \hat{\psi} = 0\)</span></p>
<p><span class="math inline">\(H_1: \hat{\psi} \ne 0\)</span></p>
<p>If we want to analyse contrasts in R, we need another R package called <em>emmeans</em>. This package contains a function called <em>emmeans</em> (yes, it has the same name as the package) that allows us to run a contrast analysis. Let’s have a look at the <em>emmeans</em> function. When we call it to analyse contrasts, we need to specify a few arguments:</p>
<ul>
<li><em>object</em> (required): an R object containing the results of an ANOVA (good thing we saved our ANOVA as an R object).</li>
<li><em>spec</em> (required): a character string or vector containing the name(s) of the grouping variable(s) in our data (in our example, the grouping variable is ‘cond’).</li>
<li><em>contr</em> (optional): a character value or list indicating the type of post-hoc comparisons; the default is NULL, but we can set it to “pairwise”, or we can define it as a list of vectors representing custom contrasts.</li>
<li><em>adjust</em> (optional): a character value indicating which method should be used to control for type-I error inflation due to multiple comparisons; default is “tukey” for Tukey’s method, but we can set it to “none” if we don’t want to adjust our <span class="math inline">\(p\)</span>-values, or we can choose a different adjustment method such as “holm” (the the Holm-Tukey method) or Bonferroni (for the Bonferroni correction).</li>
</ul>
<p>Let’s dive in an run pairwise comparisons on our ANOVA. We can tell the <em>emmeans</em> function to run pairwise contrasts by seeting the <em>contr</em> argument to “pairwise”. The function will then set up the following contrasts:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>control</th>
<th>treatment 1</th>
<th>treatment 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>contrast 1</td>
<td>1</td>
<td>-1</td>
<td>0</td>
</tr>
<tr class="even">
<td>contrast 2</td>
<td>1</td>
<td>0</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>contrast 3</td>
<td>0</td>
<td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>In the first example, we will go with the unadjusted <span class="math inline">\(p\)</span>-values. Let’s have a look at the code using the ANOVA model we saved as an R object above (“model1”). Here is the syntax.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># uncomment the next line to install the package emmeans</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("emmeans")</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load emmeans</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># pairwise comparisons without type-I error adjustment</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>One we run the code above, R will return some information in the console. Here is what it looks like:</p>
<div class="alert alret-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 cond    emmean   SE df lower.CL upper.CL
 control   97.1 1.73 87     93.7      101
 treat1   102.4 1.73 87     98.9      106
 treat2   113.3 1.73 87    109.9      117

Confidence level used: 0.95 

$contrasts
 contrast         estimate   SE df t.ratio p.value
 control - treat1    -5.23 2.44 87  -2.143  0.0349
 control - treat2   -16.20 2.44 87  -6.633  &lt;.0001
 treat1 - treat2    -10.97 2.44 87  -4.490  &lt;.0001</code></pre>
</div>
</div>
</div>
<p>The information we are interested in, is contained in the lower half of the output. There, we can see three contrasts, each comparing two of the three levels of our between-subjects variable ‘cond’. The output contains an estimate of the respective mean difference (this is the contrast value <span class="math inline">\(\hat{\psi}\)</span>) and its associated standard error (this is <span class="math inline">\(S_{\hat{\psi}}\)</span>). It also shows us the empirical <span class="math inline">\(t\)</span>-value for the contrast (dividing <span class="math inline">\(\hat{\psi}\)</span> by <span class="math inline">\(S_{\hat{\psi}}\)</span> yields this exact value) and its degrees of freedom. Here, we can see that the contrast has more degrees of freedom than a simple <span class="math inline">\(t\)</span>-test would have. Finally, the output contains the <span class="math inline">\(p\)</span>-value for each contrast. Based on this analysis, we would conclude that the effect of condition on our ANOVA was significant because all three means differ from one another.</p>
<p>Now let’s rerun the analysis while correcting for multiple comparisons. As mentioned above, we can choose from several methods that control type-I inflation. Let’s say we want to go with a classic and opt for Bonferroni’s method. This method adjusts the threshold at witch we consider an effect to be statistically significant. We now accept <span class="math inline">\(H_1\)</span> only if <span class="math inline">\(p &lt; \frac{\alpha}{k}\)</span>, where <span class="math inline">\(\alpha\)</span> is our tolerated type-I error level (e.g., <span class="math inline">\(\alpha = .05\)</span>), and <span class="math inline">\(k\)</span> is the number of post-hoc contrasts we test. What R does instead, is multiplying the unadjusted <span class="math inline">\(p\)</span>-values by <span class="math inline">\(k\)</span>. This makes it somewhat more convenient because we can keep comparing the now corrected <span class="math inline">\(p\)</span>-values to our usual tolerated type-I error level.</p>
<div class="alert alert-sucess">
<p>Are wondering what would happen if the unadjusted <span class="math inline">\(p\)</span>-value is already so large that multiplying it by the number of tests <span class="math inline">\(k\)</span> would propel it above 1? The simple answer is: nothing terrible: R caps the adjusted <span class="math inline">\(p\)</span>-values at 1 in order not to violate the laws of probability. While it is technically ‘wrong’, it is of little concerns to because the <span class="math inline">\(p\)</span>-values it concerns are so large they we would not accept <span class="math inline">\(H_1\)</span> in either the adjusted or unadjusted case.</p>
</div>
<p>Here is the code for the pairwise comparisons using Bonferroni’s method for controlling type-I error inflation (the only thing we need to change is the <em>adjust</em> argument).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pairwise comparisons with Bonferroni adjustment</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'bonferroni'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s have a look at the output in the console:</p>
<div class="alert alret-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 cond    emmean   SE df lower.CL upper.CL
 control   97.1 1.73 87     93.7      101
 treat1   102.4 1.73 87     98.9      106
 treat2   113.3 1.73 87    109.9      117

Confidence level used: 0.95 

$contrasts
 contrast         estimate   SE df t.ratio p.value
 control - treat1    -5.23 2.44 87  -2.143  0.1048
 control - treat2   -16.20 2.44 87  -6.633  &lt;.0001
 treat1 - treat2    -10.97 2.44 87  -4.490  0.0001

P value adjustment: bonferroni method for 3 tests </code></pre>
</div>
</div>
</div>
<p>The information looks very similar to what we saw when we ran the uncorrected pairwise comparisons. The are only two differences: first, R will state at the bottom of the table that the <span class="math inline">\(p\)</span>-values were adjusted using Bonferroni’s method for three tests. Second, the <span class="math inline">\(p\)</span>-values differ. From looking at the first <span class="math inline">\(p\)</span>-value (the one for the contrast comparing treatment 1 to the control group) we can confirm that R has tripled the original <span class="math inline">\(p\)</span>-value (the difference at the fourth decimal is due to rounding). If we choose to use a Bonferroni correction for the post-hoc comparisons, our conclusions about the result of the ANOVA change slightly. Now, we would state - with the usual confidence - that the significant effect the ANOVA is due to the mean of the second treatment group differing from both the control group’s mean and that from treatment 1. However, we cannot say whether scores in treatment 1 differ from the control group.</p>
<p>Finally, let’s consider using a less conservative adjustment method, namely Tukey’s method, also known as Tukey’s honestly significant difference (HSD). In technical terms, HSD computes the critical mean difference for which a pairwise comparison is considered significant, and then judges each comparison by that difference. The test statistic <span class="math inline">\(q\)</span> follows the Studentised range distribution, the shape of which depends on the number of groups <span class="math inline">\(k\)</span> and the sample size <span class="math inline">\(N\)</span> (via the distribution’s degrees of freedom). Because the distribution of the <span class="math inline">\(q\)</span>-statistic considers the number of groups, the HSD adjusts for multiple comparisons. Again, the oly theing we need to change about our syntax is the <em>adjust</em> argument (see below):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pairwise comparisons using Tukey's method</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'tukey'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s again inspect the console output</p>
<div class="alert alret-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 cond    emmean   SE df lower.CL upper.CL
 control   97.1 1.73 87     93.7      101
 treat1   102.4 1.73 87     98.9      106
 treat2   113.3 1.73 87    109.9      117

Confidence level used: 0.95 

$contrasts
 contrast         estimate   SE df t.ratio p.value
 control - treat1    -5.23 2.44 87  -2.143  0.0872
 control - treat2   -16.20 2.44 87  -6.633  &lt;.0001
 treat1 - treat2    -10.97 2.44 87  -4.490  0.0001

P value adjustment: tukey method for comparing a family of 3 estimates </code></pre>
</div>
</div>
</div>
<p>Once more, the output remains largely the same, the only difference being the <span class="math inline">\(p\)</span>-values and the statement about how the <span class="math inline">\(p\)</span>-values were adjusted. We can see that - similar to the Bonferroni - correction, R uses a multiplier on the <span class="math inline">\(p\)</span>-values rather than lowering the tolerated type-I error level, which makes life a little easier for us because we can still use our conventional <span class="math inline">\(\alpha\)</span>-level to asses the statistical significance of the tests. Although the Tukey correction is less severe than the Bonferroni correction, the result is qualitatively similar: we can confirm that treatment 2 scores differ from those of the other two conditions, but we cannot say whether scores in treatment 1 differ from those in the control group.</p>
</section>
<section id="custom-post-hoc-contrasts" class="level3">
<h3 class="anchored" data-anchor-id="custom-post-hoc-contrasts">Custom post-hoc contrasts</h3>
<p>The final way to run post-hoc tests we will consider here is to run custom contrasts. What this means is that we define ourselves how we want to compare the group means in case of a significant effect in the ANOVA. When using custom contrasts, we can choose how many comparisons we run, which means we want to compare, and how to compare them.The only thing we need to keep in mind is that the contrast weights must add to zero (R does not check this for us; the code will run even if the contrast sum does not add to zero, but the result may be nonsense).</p>
<p>For example, we could compare two group means (just as we did with the pairwise comparisons), but we could also test whether two groups differ from a third.</p>
<p>Let us go back to our ANOVA example and assume that we want to run two post-hoc tests. The first tests whether having any treatment leads to different scores than being in the control condition. The second tests whether the effectiveness of the two treatments differs. Here is what the two contrasts would look like:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>control</th>
<th>treatment 1</th>
<th>treatment 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>contrast 1</td>
<td>-1</td>
<td>+0.5</td>
<td>+0.5</td>
</tr>
<tr class="even">
<td>contrast 2</td>
<td>0</td>
<td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>Let’s dissect that! For contrast 1, we compare the control group with the mean of the two treatment groups. In contrast 2, we compare only the two treatment groups; the 0 weight for the control condition means that its mean does not play any role in this contrast.</p>
<p>How do we tell R that we want to run custom contrasts? We can do so using the <em>contr</em> argument of the <em>emmeans</em> function. To be specific, we need to define this argument as a list in which each element is one contrast.</p>
<p>When defining the list of contrasts, each contrast must be a numeric vector of length <span class="math inline">\(k\)</span>, where <span class="math inline">\(k\)</span> is the number of groups in the grouping variable that we fed into the <em>emmeans</em> function (in our case 3). If we chose the wrong vector length, we will receive an error message. We also need to make sure that the sum of each contrast vector is zero (see above). Finally, we can (but do not have to) create these vectors as named elements of the list. Naming the vectors may lead to output that is slightly easier to make sense of.</p>
<p>Here, we need to decide whether we save the list of contrasts as a separate object or whether we feed the <em>emmeans</em> function a call of the <em>list</em> function (the result will be the same, so it is simply a matter of preference). Now let’s look at the R code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 1: separate objects</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create a list containing the custom contrasts</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>my_contrasts <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> my_contrasts, <span class="at">adjust =</span> <span class="st">'none'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 2: don't create a separate list</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="fu">list</span>(</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>          <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>          <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)), </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running either version of the code will prompt R to test the contrasts and adjust the <span class="math inline">\(p\)</span>-values according to Bonferroni’s method (of course we could select a different adjustment method or turn if off by changing the <em>adjust</em> argument accordingly). We will receive the following console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 cond    emmean   SE df lower.CL upper.CL
 control   97.1 1.73 87     93.7      101
 treat1   102.4 1.73 87     98.9      106
 treat2   113.3 1.73 87    109.9      117

Confidence level used: 0.95 

$contrasts
 contrast         estimate   SE df t.ratio p.value
 treat_vs_control     10.7 2.12 87   5.066  &lt;.0001
 treat1_vs_treat2    -11.0 2.44 87  -4.490  &lt;.0001</code></pre>
</div>
</div>
</div>
<p>As we can see, R now returns a table with two contrast tests. Since we named the contrasts properly, it is easy to see what these contrasts tested. For each contrast, R will tell us the estimated mean difference, the associated standard error, and the degrees of freedom (<span class="math inline">\(n-k\)</span>, similar to the pairwise comparisons described above). It will also show us the <span class="math inline">\(t\)</span>-value and <span class="math inline">\(p\)</span>-value for each contrast.</p>
<p>In our example, both contrasts are significant. This means, we can state - with the usual confidence - that the ANOVA was significant because a) getting a treatment leads to different scores than getting no no treatment (control condition), and b) the treatments differ in effectiveness.</p>
<p>But what about multiple comparisons? So far, we have not corrected our custom contrasts for multiple comparisons, but we can do so if we want to. The only thing we need to consider is that we cannot use Tukey’s method as it is specific to pairwise comparisons (oddly enough, Tukey’s method won’t work even if we manually specify pairwise comparisons - if we want to use the HSD method,m we need to set the <em>contr</em> argument to “pairwise”).</p>
<p>To adjust for multiple comparisons, we can again specify the argument <em>adjust</em>. If we use custom contrasts, the default for this argument is actually “none”, but we can set it to “bonferroni” (for the classic Bonferroni correction) or “holm” (for the slightly lees conservative Holm-Bonferroni method) instead. Let’s go with Bonferroni. Here is the code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests using "contrast" and correct</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for multiple comparisons using Bonferroni's method</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="fu">list</span>(</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)), </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">adjust =</span> <span class="st">'bonferroni'</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s look at the console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 cond    emmean   SE df lower.CL upper.CL
 control   97.1 1.73 87     93.7      101
 treat1   102.4 1.73 87     98.9      106
 treat2   113.3 1.73 87    109.9      117

Confidence level used: 0.95 

$contrasts
 contrast         estimate   SE df t.ratio p.value
 treat_vs_control     10.7 2.12 87   5.066  &lt;.0001
 treat1_vs_treat2    -11.0 2.44 87  -4.490  &lt;.0001

P value adjustment: bonferroni method for 2 tests </code></pre>
</div>
</div>
</div>
<p>As we can see, not much has changed in terms of statistical significance, which makes sense because the unadjusted <span class="math inline">\(p\)</span>-values were already very low. However, R now tells us at the bottom of the table that <span class="math inline">\(p\)</span>-values were adjusted using the Bonferroni method.</p>
<div class="alert alert-info">
<p>Custom contrasts are really useful because of their flexibility. They allow us to test very specific hypotheses. In fact, if we can state in advance which means in our design should differ (for example, because we have a strong theory to base our hypotheses on), we can technically skip the ANOVA altogether and instead run only the contrast tests. In those cases, we speak of a-priori contrasts.</p>
</div>
</section>
<section id="a-concluding-remark-on-post-hoc-comparisons" class="level3">
<h3 class="anchored" data-anchor-id="a-concluding-remark-on-post-hoc-comparisons">A concluding remark on post-hoc comparisons</h3>
<p>We started the journey into post-hoc analyses using the metaphor of the ANOVA as firing a shotgun into thick fog which - in case we hit something - necessitates wandering into the fog in order to find out what exactly we hit. As the examples above show, the answer to that crucial question depends on which post-hoc comparisons we run (simple <span class="math inline">\(t\)</span>-tests, pairwise comparison contrasts, or custom contrasts) and whether and how we control for type-I error inflation due to multiple comparisons.</p>
<p>When trying to disentangle a significant effect in an ANOVA, we may find ourselves faced with multiple options, each of which is valid and can be argued for convincingly. However, even subtle differences between these options may lead to qualitatively different conclusions. The practical advice here is to preregister exactly which tests we will run in case an ANOVA yields a significant result (ideally by providing the R code for the post-hoc analysis).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>