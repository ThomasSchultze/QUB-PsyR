<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.258">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUB-PsyR - Repeated measures and mixed ANOVAs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/QUBlogoWsmall.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">QUB-PsyR</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="../intro/intro1.html">
 <span class="dropdown-text">R and RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro2.html">
 <span class="dropdown-text">Running Code in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro3.html">
 <span class="dropdown-text">Objects and Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro4.html">
 <span class="dropdown-text">Data Frames and Lists</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro5.html">
 <span class="dropdown-text">Saving and Loading Data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-working-with-r-objects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Working with R Objects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-working-with-r-objects">    
        <li>
    <a class="dropdown-item" href="../working/working1.html">
 <span class="dropdown-text">Binary Operators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working2.html">
 <span class="dropdown-text">Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working3.html">
 <span class="dropdown-text">Numerical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working4.html">
 <span class="dropdown-text">Logical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working5.html">
 <span class="dropdown-text">R Packages</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-inference" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Inference</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-statistical-inference">    
        <li>
    <a class="dropdown-item" href="../inference/inference0.html">
 <span class="dropdown-text">A Primer on Statistical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference1.html">
 <span class="dropdown-text">The t-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference2.html">
 <span class="dropdown-text">The Chi²-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference3.html">
 <span class="dropdown-text">Correlations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference4.html">
 <span class="dropdown-text">One-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference5.html">
 <span class="dropdown-text">Two-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference6.html">
 <span class="dropdown-text">Repeated measures and mixed ANOVAs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference7.html">
 <span class="dropdown-text">Simple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference8.html">
 <span class="dropdown-text">Multiple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference9.html">
 <span class="dropdown-text">Multi-level models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-data-visualisation" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Data Visualisation</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-data-visualisation">    
        <li>
    <a class="dropdown-item" href="../graphs/graphs0.html">
 <span class="dropdown-text">Preface</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs1.html">
 <span class="dropdown-text">Histograms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs2.html">
 <span class="dropdown-text">Scatterplots</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs3.html">
 <span class="dropdown-text">Violin plots</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-data-wrangling" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Data Wrangling</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-data-wrangling">    
        <li>
    <a class="dropdown-item" href="../wrangling/wrangling0.html">
 <span class="dropdown-text">Preface</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../wrangling/wrangling1.html">
 <span class="dropdown-text">Extracting rows and columns</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Repeated measures and mixed ANOVAs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>So far, we have covered ANOVAs for designs, in which the explanatory variables varied between subjects. We will now turn to cases, in which all or at least some of these factors vary within subjects. Although these cases are a little more complicated, they follow the same logic of taking the overall variance of the outcome of interest and partitioning it.</p>
<p>In a repeated measures ANOVA (also sometimes referred to as within-subjects ANOVA), we are interested in whether there are mean differences between two or more variables measured among the same participants. This could be the same variable we measure at different times, for example when we are interested in changes over time, or responses to different questions we asked our participants, for example how much they like various colours.</p>
<section id="one-factorial-repeated-measures-anova" class="level2">
<h2 class="anchored" data-anchor-id="one-factorial-repeated-measures-anova">One-factorial repeated measures ANOVA</h2>
<p>The one-factorial case of the repeated measures ANOVA is an extension of the paired <span class="math inline">\(t\)</span>-test. The difference to the one-factorial between-subjects ANOVA is that each participant provides a response at all levels of the within-subjects factor (if at least one of the responses is missing, that participant is lost for the analysis). The question now is how to partition the variance of the observations or - to be more precise - the corresponding sums of squares.</p>
<p>In a first step, we can partition the total sum of squares into variability between participants and variability within participants:</p>
<p><span class="math display">\[SS_{total} = SS_{betweenP} + SS_{withinP}\]</span></p>
<p>Here, <span class="math inline">\(SS_{betweenP}\)</span> represents variability that we can attribute to idiosyncrasies of our participants, meaning that participants differ systematically in their responses. Depending on what we are investigating the reasons for such systematic differences could be inter-individual differences in terms of personality, gender, education, or general cognitive ability. They could also stem from differences in task-related aptitude or current motivational or affective states. Whatever the reasons, if there is variation between participants, we can state that, averaged across all levels of our factor, some participants have higher or lower levels in our outcome variable than others.</p>
<p>In most cases, we are more interested in variability within participants represented by the <span class="math inline">\(SS_{withinP}\)</span>. The reason is that this variability contains not only the measurement error (i.e., unsystematic or unexplained variability of responses each participants provides), but also systematic variability between the levels of our within-subjects factor. This means that we can further partition the <span class="math inline">\(SS_{withinP}\)</span> as follows:</p>
<p><span class="math display">\[SS_{withinP} = SS_{betweenC} + SS_{error}\]</span> Here, <span class="math inline">\(SS_{betweenC}\)</span> represent the part of the total variability of <span class="math inline">\(X\)</span> that we can attribute to the variation of our within-subjects factor. This is what we are ultimately interested in when we run a repeated measures ANOVA. The error term <span class="math inline">\(SS_{error}\)</span> accordingly includes all variability that we cannot attribute to the variation in the within-subjects factor. In sum, we can partition the total sum of squares as follows:</p>
<p><span class="math display">\[SS_{total} = SS_{betweenP} + SS_{betweenC} + SS_{error}\]</span> The first step is to compute the total sum of squares. We do so by collapsing across all participants <span class="math inline">\(i\)</span> and all <span class="math inline">\(j\)</span> levels of the within-subjects factor <span class="math inline">\(A\)</span>. Thus, our total sum of squares looks as usual:</p>
<p><span class="math display">\[SS_{total} = \sum_{i=1}^{N} \sum_{j=1}^{J} (x_{ij} - \bar{x})^2\]</span></p>
<p>We next compute the <span class="math inline">\(SS_{betweenP}\)</span>, for the sake of completeness. Technically, we do not really need it because the information we are actually interested in lies completely within participants. In order to compute the <span class="math inline">\(SS_{betweenP}\)</span>, we pretend that there is no more variability within participants. We can so by replicate each participants’ responses by their mean across all factor levels. That is, we pretend that a participant always responds with the exact same score on all measurements.</p>
<p><span class="math display">\[SS_{betweenP} = J\sum_{i = 1}^{N}(\bar{x}_i-\bar{x})^2 \]</span></p>
<p>Here, <span class="math inline">\(J\)</span> is the number of factor levels and <span class="math inline">\(N\)</span> is the sample size.</p>
<p>We next compute the <span class="math inline">\(SS_{withinP}\)</span>. Since we are only interested in how much variation there is in the various responses participants provided, we must pretend that there is no more variability between participants. We do so by substituting the grand mean <span class="math inline">\(\bar{x}\)</span> with each participant’s own mean response across all factor levels <span class="math inline">\(\bar{x_i}\)</span>:</p>
<p><span class="math display">\[SS_{withinP} = \sum_{i=1}^{N}\sum_{j=1}^{J}(x_{ij}-\bar{x}_{i})^2\]</span> Here, <span class="math inline">\(N\)</span> is again the sample size, <span class="math inline">\(J\)</span> is the number of factor levels, <span class="math inline">\(X_{ij}\)</span> is the response of the <span class="math inline">\(i\)</span>th participant to the <span class="math inline">\(j\)</span>th level of our factor, and <span class="math inline">\(\bar{x_i}\)</span> is the mean response of the <span class="math inline">\(i\)</span>th participant across all factor levels.</p>
<p>Now that we have computed the <span class="math inline">\(SS_{withinP}\)</span>, it is time to compute the variability in our data that is attributable to the variation of our factor, namely <span class="math inline">\(SS_{betweenC}\)</span>. We compute is in the same fashion in which we computed the <span class="math inline">\(SS_{between}\)</span> in the one-factorial case, that is, we substitute each individual response within one factor level by the respective mean response.</p>
<p><span class="math display">\[SS_{betweenC} = N\sum_{j=1}^{J}(\bar{x}_j-\bar{x})^2\]</span> Here, <span class="math inline">\(N\)</span> is the sample size, <span class="math inline">\(J\)</span> is the number of factor levels, <span class="math inline">\(\bar{x}\)</span> is the grand mean, and <span class="math inline">\(\bar{x_j}\)</span> is the cell mean for the <span class="math inline">\(j\)</span>th factor level.</p>
<p>Now that we know both the variability within participants <span class="math inline">\(SS_{withinP}\)</span> and that part of it that we can attribute to variability in our factor <span class="math inline">\(SS_{betweenC}\)</span>, we can compute <span class="math inline">\(SS_{error}\)</span> via simple subtraction:</p>
<p><span class="math display">\[SS_{error} = SS_{withinP} - SS_{betweenC}\]</span>.</p>
<p>We can now compute the <span class="math inline">\(F\)</span>-statistic that will tell us whether the variability between the factor levels is large enough to constitute a significant effect. To do so, we compute the <span class="math inline">\(MS_{betweenC}\)</span> and <span class="math inline">\(MS_{error}\)</span> by dividing the respective sums of squares by their degrees of freedom and then take their ratio:</p>
<p><span class="math display">\[\frac{MS_{betweenC}}{MS_{error}} = \frac{\frac{SS_{betweenC}}{J-1}}{\frac{SS_{error}}{(J-1)\times(N-1)}} = F_{J-1;(J-1)\times{(N-1)}}\]</span> Just as in the between-subjects case, we can now test whether the within-subjects factor, let’s call it <span class="math inline">\(A\)</span>, has an effect on the outcome variable. Remember that:</p>
<p><span class="math inline">\(\alpha_j = \mu_j - \mu\)</span></p>
<p>This means that the effect of the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span>, <span class="math inline">\(\alpha_j\)</span> is the difference between the true group mean <span class="math inline">\(\mu_j\)</span> and the true grand mean <span class="math inline">\(\mu\)</span>.</p>
<p>Just as in the between-subjects ANOVA, the Null hypothesis is that all <span class="math inline">\(\alpha_j\)</span> are zero (i.e., all cell means are equal). The alternative hypothesis is that not all group means are equal or, put differently, that at least one of the <span class="math inline">\(\alpha_j\)</span> is non-zero.</p>
<p><span class="math inline">\(H0:\alpha_j = 0 \quad \forall j\)</span></p>
<p><span class="math inline">\(H1: \lnot H_0\)</span></p>
<section id="running-a-repeated-measure-anova-in-r" class="level3">
<h3 class="anchored" data-anchor-id="running-a-repeated-measure-anova-in-r">Running a repeated measure ANOVA in R</h3>
<p>Since we already know how to run between-subjects ANOVAs in R, it is fairly easy to run a repeated measures ANOVA. We will use the same package and function we used for the between-subjects ANOVAs, namely the <strong><code>aov_ez()</code></strong> function from R package <code>* afex*</code>. The only difference is that we will use the function argument <code>wihtin</code> instead of <code>between</code> to tell R the name of our within-subjects factor.</p>
<p>As always, we need some data first. Let’s assume that we ran a study with a within-subjects design, in which 30 participants worked three memory tasks that only differ in difficulty (let’s assume that we counterbalanced the order so we do not need to concern ourselves with order effects). In other words, we have a within-subjects factor called “difficulty” with three levels, and we can now test whether participants’ task performance differs according this factor. We will call the data frame containing the data <em>df1</em>. Here is what the data looks like.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID difficulty performance
1  1       easy   2.1646466
2  1   moderate   0.7448755
3  1       hard   1.3471731
4  2       easy   2.0451407
5  2   moderate  -0.2245538
6  2       hard  -1.2001469</code></pre>
</div>
</div>
</div>
<p>We can now run the repeated measures ANOVA using the following syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the library afex</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(afex)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># run the ANOVA and save it as a new object</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>aov1 <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">dv =</span> <span class="st">'performance'</span>, </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">within =</span> <span class="st">'difficulty'</span>, <span class="at">data =</span> df1)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># return the result of the ANOVA</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>aov1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If we run the code above, R will produce the following output in the console:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: performance
      Effect          df  MSE         F  ges p.value
1 difficulty 1.91, 55.25 0.49 27.22 *** .255   &lt;.001
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1

Sphericity correction method: GG </code></pre>
</div>
</div>
</div>
<p>The information is similar to the one we got in the between-subjects case, that is, R displays the name of our factor, <span class="math inline">\(F\)</span>-statistic and its degrees of freedom, an estimate of the effect size <span class="math inline">\(\eta_2\)</span>, and the <span class="math inline">\(p\)</span>-value.</p>
<p>Note that the analysis yields <strong>fractional degrees of freedom</strong> that are slightly lower then the ones we would have expected based on the descriptions above. The reason is that the <strong><code>aov_ez()</code></strong> function corrects for violations of the <strong>sphericity assumption</strong> per default using the Greenhouse-Geisser method.</p>
<div class="alert alert-success">
<p>As you may recall, <strong>sphericity</strong> is one of the assumptions we make in order for repeated measures ANOVAs to provide meaningful results. Sphericity means that the variances of all pairwise differences of our factor levels are equal. In a design with a three-level factor, this means that we have three possible differences: <span class="math inline">\(\Delta_{1;2}\)</span> is the difference between factor levels 1 and 2, <span class="math inline">\(\Delta_{1;3}\)</span> is the difference between factor levels 1 and 3, and <span class="math inline">\(\Delta_{2;3}\)</span> is the difference between levels 2 and 3. The assumption of sphericity in this case states that if we computed the variances of each of the <span class="math inline">\(\Delta\)</span>a, they would all be equal.</p>
<p>Often, people test whether this assumption is violated and decide only to control for its violation when the respective test does not justify retaining the Null hypothesis that the variances of the pairwise differences between factor levels are equal. However, similar to the paired <span class="math inline">\(t\)</span>-test, R takes a different approach and corrects the degrees of freedom for non-sphericity unless we explicitly ask it not to.</p>
</div>
<p>Generally speaking, there is no reason to turn off the default Greenhouse-Geisser correction. However, in some cases, we may want to run the ANOVA without correcting for egocentricity (for example, when trying to reproduce results of published studies), or we may want to change the correction method to the Huynh-Feldt method.</p>
<p>We can change the default for the correction of non-sphericity using function argument of the <strong><code>aov_ez()</code></strong> function called <code>anova-table</code>. This argument is a list that allows us to change several aspects of the ANOVA, but for now we only need to define one parameter in that list called <code>correction</code>, which is a character string indicating how we want to correct for non-sphericity in an aNOVA with at least one within-subjects factor. It defaults to “GG” (Greenhouse-Geisser method), but we can alternative set it to “none” (no correction) or HF(Huynh-Feldt method).</p>
<p>Let’s say we want to turn off the non-sphericity correction. Here is what the syntax looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the library afex</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(afex)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># run the ANOVA and save it as a new object;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># also turn off correction for non-sphericity</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>aov1b <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">dv =</span> <span class="st">'performance'</span>, </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">within =</span> <span class="st">'difficulty'</span>, <span class="at">data =</span> df1,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">anova_table =</span> <span class="fu">list</span>(<span class="at">correction =</span> <span class="st">'none'</span>))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># return the result of the new ANOVA</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>aov1b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see in the console, the degrees of freedom now match the ones stated above. Since the violation of sphericity was not severe in the first place (we can see this from the corrected degrees of freedom being very close to the uncorrected ones), the results remain qualitatively similar.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: performance
      Effect    df  MSE         F  ges p.value
1 difficulty 2, 58 0.47 27.22 *** .255   &lt;.001
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
</section>
<section id="disentangling-significant-effects-in-repeated-measures-anovas" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-significant-effects-in-repeated-measures-anovas">Disentangling significant effects in repeated measures ANOVAs</h3>
<p>As in the between-subjects case, a significant effect in a repeated measures ANOVA becomes difficult to interpret without further analysis once we have three or more factor levels. The simple conclusion that “not all means are equal” is rarely satisfactory. Therefore, we need to investigate where exactly the mean differences originate using post-hoc comparisons.</p>
<p>The good news is that it works pretty much in the same fashion as it does for between-subjects ANOVAs. That is, we can use the <strong><code>emmeans()</code></strong> function from the <em><code>emmeans</code></em> package to test pairwise comparisons or custom contrasts for statistical significance. If we were, for example, interested in the pairwise comparisons, the syntax would look as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the library emmeans</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute pairwise comparisons for the within-subjects factor</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(aov1, <span class="at">specs =</span> <span class="st">'difficulty'</span>, </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">correction =</span> <span class="st">'tukey'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that since ‘tukey’ is the default for the <code>correction</code> argument, we could have omitted it. Now let’s have a look at the console output.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 difficulty  emmean    SE df lower.CL upper.CL
 easy        1.1221 0.148 29    0.820    1.424
 hard       -0.0738 0.177 29   -0.435    0.288
 moderate    0.9778 0.181 29    0.608    1.347

Confidence level used: 0.95 

$contrasts
 contrast        estimate    SE df t.ratio p.value
 easy - hard        1.196 0.160 29   7.472  &lt;.0001
 easy - moderate    0.144 0.194 29   0.743  0.7402
 hard - moderate   -1.052 0.175 29  -6.006  &lt;.0001

P value adjustment: tukey method for comparing a family of 3 estimates </code></pre>
</div>
</div>
</div>
<p>One thing is worth noting here: other than in the between-subjects case, the post-hoc contrasts do not benefit from increased degrees of freedom. Instead, they are equivalent to simple paired <span class="math inline">\(t\)</span>-tests. The reason is that, here, we already use information from all available participants when estimating the error term of the pairwise comparisons.</p>
</section>
</section>
<section id="repeated-measures-anovas-with-multiple-factors" class="level2">
<h2 class="anchored" data-anchor-id="repeated-measures-anovas-with-multiple-factors">Repeated measures ANOVAs with multiple factors</h2>
<p>Just as in the between-subjects case, we can run a repeated measures ANOVA with two or more within-subjects factors. Here, we will focus on the two-factorial case, but from there, we can easily extrapolate to more complex designs.</p>
<p>If we have two within-subjects factors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, systematic variance between conditions can stem from the main effects of these factors or their interaction. As such, we can decompose the variability between conditions represented by <span class="math inline">\(SS_{betweenC}\)</span> as follows:</p>
<p><span class="math display">\[SS_{betweenC} = SS_A + SS_B + SS_{A \times B}\]</span> The test logic is, again, similar to that of the two-factorial between-subjects ANOVA, that is, we can test the two main effects and the interaction effect for statistical significance using <span class="math inline">\(F\)</span>-ratios. To do so, we first need to compute the <span class="math inline">\(MS\)</span> of the effect we are interested in as the ratio of its <span class="math inline">\(SS\)</span> and its degrees of freedom, and the divide this <span class="math inline">\(MS\)</span> by the <span class="math inline">\(MS_{error}\)</span> which we compute in the exact same way as we did in the one-factorial repeated measures ANOVA (see above).</p>
<p>Using that approach, we can test: <span class="math inline">\(H_{0_A}\)</span> (all marginal means of factor A are equal), <span class="math inline">\(H_{0_B}\)</span> (all marginal means of factor B are equal), and <span class="math inline">\(H_{0_{A \times B}}\)</span> (the combination of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> has no effect beyond the the respective main effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>).</p>
<section id="running-two-factorial-repeated-measures-anovas-in-r" class="level3">
<h3 class="anchored" data-anchor-id="running-two-factorial-repeated-measures-anovas-in-r">Running two-factorial repeated measures ANOVAS in R</h3>
<p>Before we can look at the code for a two-factorial repeated measures ANOVA, we need some data. Let’s assume we ran an experiment studying 50 participants’ willingness to forgive a transgression by another person in a fictional situation on a scale from 1 (not at all) to 6 (certainly). Let’s further assume that we manipulate two variables: the severity of the transgression (low, moderate, or high) and the apparent socio-economic status (SES) of the other person (low vs.&nbsp;high). This leaves us with a <span class="math inline">\(2 \ times 3\)</span> within-subjects design. Here is an excerpt of some simulated data for this study which are contained in the data <em>df2</em>.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID severity  SES forgive
1  1      low high       3
2  2      low high       3
3  3      low high       3
4  4      low high       3
5  5      low high       3
6  6      low high       4</code></pre>
</div>
</div>
</div>
<p>We can now run the two-factorial repeated measures ANOVA using the <strong><code>aov_ez()</code></strong> function. Since we have two within-subjects factors, we need to feed the function a character vector containing both factor’s names as the <code>within</code> argument. here is what the code looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run a two-factorial within-subjects ANOVA</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>aov2 <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">within =</span> <span class="fu">c</span>(<span class="st">'severity'</span>, <span class="st">'SES'</span>), </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> df2, <span class="at">dv =</span> <span class="st">'forgive'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># display the ANOVA results</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>aov2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once we run the code above, here is what appears in the console as output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: forgive
        Effect          df  MSE         F  ges p.value
1     severity 1.93, 94.57 0.53 10.57 *** .032   &lt;.001
2          SES       1, 49 0.34      1.40 .001    .243
3 severity:SES 1.55, 76.13 0.81    4.47 * .017    .022
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1

Sphericity correction method: GG </code></pre>
</div>
</div>
</div>
<p>As we can see, the ANOVA table R returns contains information on the two main effects and the interaction. For the two significant effects, the main effect of the severity of the transgression and the interaction of severity and SES, we can also see that the <strong><code>aov_ez()</code></strong> function adjusted the degrees of freedom to adjust non-sphericity. There is no such adjustment for the main effect of SES because it has only two levels (if we wanted to turn the adjustment off or set it to the Huynh-Feldt method, we could do it using the <code>anova_table</code> argument, see above).</p>
</section>
<section id="disentangling-effects-in-a-two-factorial-repeated-measure-anova" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-effects-in-a-two-factorial-repeated-measure-anova">Disentangling effects in a two-factorial repeated measure ANOVA</h3>
<p>Similar to the between-subjects case, how we go about disentangling the effects in a two-factorial repeated measure ANVOA depends critically on whether the interaction was statistically significant. Remember that, as general rule, we should only interpret main effects if there is either no evidence of an interaction in our analysis or if the interaction is ordinal.</p>
<p>Let’s have a look at the results using a violin plot (the black dots show the means for each condition while the lines behind them represent the 95% confidence intervals):</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference6_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The graphical inspection already suggests that we do not have an ordinal interaction, which means that we should focus on the interaction when interpreting the results and not interpret the main effect of severity. Of course, we could also run a statistical analysis instead of the visual inspection by checking for each level of the severity factor whether there is a significant effect of SES in the same direction.</p>
<p>We can do that using the <strong><code>emmeans()</code></strong> function. However, we will use the <code>specs</code> argument in a slightly different way. Instead of defining it as a character vector containing our two factors, we will define it as a <strong>formula</strong>. Specifically, we will tell the <strong><code>emmeans()</code></strong> function to compare the means of the factor for which the ANOVA yielded a significant main effect (severity) separately for each level of the other factor (SES). Here is that the syntax looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain pairwise comparisons for SES for each level of severity</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="sc">~</span> severity<span class="sc">|</span>SES, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'tukey'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, R will know that we enter a formula when specifying the <code>specs</code> argument because we lead with a <strong>tilde</strong> operator (<strong><code>~</code></strong>). The rest of the definition of <code>specs</code> reads as <strong>SES by severity</strong>. Now let’s have a look at the output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
SES = high:
 severity emmean    SE df lower.CL upper.CL
 low        3.78 0.162 49     3.45     4.11
 moderate   3.68 0.152 49     3.37     3.99
 high       3.64 0.151 49     3.34     3.94

SES = low:
 severity emmean    SE df lower.CL upper.CL
 low        3.96 0.148 49     3.66     4.26
 moderate   3.72 0.134 49     3.45     3.99
 high       3.18 0.139 49     2.90     3.46

Confidence level used: 0.95 

$contrasts
SES = high:
 contrast        estimate    SE df t.ratio p.value
 low - moderate      0.10 0.188 49   0.532  0.8559
 low - high          0.14 0.157 49   0.894  0.6463
 moderate - high     0.04 0.143 49   0.280  0.9577

SES = low:
 contrast        estimate    SE df t.ratio p.value
 low - moderate      0.24 0.166 49   1.450  0.3237
 low - high          0.78 0.129 49   6.061  &lt;.0001
 moderate - high     0.54 0.115 49   4.694  0.0001

P value adjustment: tukey method for comparing a family of 3 estimates </code></pre>
</div>
</div>
</div>
<p>As usual, calling the <strong><code>emmeans()</code></strong> function yields two tables, one containing the means (in this case the means of each level of SES for each level of severity), and another containing the contrast tests we asked for. In our case, there are three contrasts for each level of SES since we run pairwise comparisons on a three-level factor (severity). As we can see, the severity of the transgression has statistically significant effects only when SES is low. Here, the willingness to forgive is higher when severity is low as compared with highly severe transgressions or when it is moderately severe instead of highly severe. Since the corresponding comparisons are not significant for high SES, we cannot say whether there is a true main effect of severity. That is, the statistical analysis confirms the graphical analysis and tells us not to interpret the main effect of severity.</p>
<div class="alert alert-info">
<p>In the example above, we chose the Tukey’s method to adjust for multiple comparisons. Note, however, that the <strong><code>emmeans()</code></strong> function did not adjust for six test even though we ran six tests in total.</p>
<p>Instead, the function adjusted for three tests in each fo the two sets of tests. The same would have happened had we chosen a different adjustment method such as Bonferroni’s method.</p>
<p>What this means is that we need to consider that this way of adjusting for multiple comparisons is more liberal than correcting for all tests we ran post-hoc.</p>
<p>If we wanted to adjust for all tests, the most straightforward approach would be to specify the contrasts we are interested in manually by feeding the <code>contr</code> argument a list of vectors containing the contrast weights.</p>
</div>
<p>Now that we know that there is an interaction in our data that is not ordinal, we know that we should not interpret the main effects. We do, however, need to understand the nature of the interaction effect. We already know something about the interaction because we ran pairwise comparisons of the three levels of our severity factor for each level of SES.</p>
<p>We can now run the complementary analysis by testing for differences between the two levels of SES for each level of severity of the transgression. If we do not want to adjust for multiple comparisons, we can use the formula-based approach to specifying the <code>specs</code> argument (since there is only one comparison for each level of severity, the function will not adjust the <span class="math inline">\(p\)</span>-values). Here is what the syntax looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run pairwise comparisons of SES for each level of severity</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="sc">~</span> SES<span class="sc">|</span>severity,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s have a look at the output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run pairwise comparisons of SES for each level of severity</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="sc">~</span> SES<span class="sc">|</span>severity,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>As we can see, only one of the comparisons is statistically significant. That is, while we cannot say based on the data whether SES affects the willingness to forgive slightly or moderately severe transgressions, SES makes a difference when transgressions are severe.</p>
<p>Finally, let’s consider the scenario, in which there is no significant interaction between the two within-subjects variables or in which the interaction turns out to be ordinal. In this case, we can actually interpret main effects. This means that we also need to disentangle main effects if the respective variable has more than two levels. We can, once again, do that using the <strong><code>emmeans()</code></strong> function by running pairwise comparisons on the marginal means. To this end, we need to specify the <code>specs</code> argument as the name of the factor we are interested in and omitting the other factor. Let’s do that using the example data (neglecting for a moment that the interaction was not ordinal). Here is what the code would look like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run pairwise comparisons on the marginal means of severity of transgressions by collapsing across the two levels of SES</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="st">"severity"</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span><span class="st">'tukey'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s have a look at the output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 severity emmean    SE df lower.CL upper.CL
 low        3.87 0.129 49     3.61     4.13
 moderate   3.70 0.125 49     3.45     3.95
 high       3.41 0.132 49     3.14     3.68

Results are averaged over the levels of: SES 
Confidence level used: 0.95 

$contrasts
 contrast        estimate     SE df t.ratio p.value
 low - moderate      0.17 0.1103 49   1.541  0.2808
 low - high          0.46 0.0978 49   4.705  0.0001
 moderate - high     0.29 0.0949 49   3.057  0.0099

Results are averaged over the levels of: SES 
P value adjustment: tukey method for comparing a family of 3 estimates </code></pre>
</div>
</div>
</div>
<p>R tells us that the results of the pairwise comparisons are averaged across the levels of SES, just as we intended. We can see that willingness to forgive is higher for transgression of low or moderate severity when compared with severe transgressions. If there was no interaction in our data or if the interaction was ordinal, we could then conclude that this is a general pattern.</p>
</section>
</section>
<section id="mixed-anovas" class="level2">
<h2 class="anchored" data-anchor-id="mixed-anovas">Mixed ANOVAs</h2>
<p>We speak of a mixed ANOVA when the research design contains at least one between-subjects factor and at least one within-subjects factor. A very prominent type of studies that fall into this category is the randomised control trial with pre, post, and follow-up measures.</p>
<p>We already know how to partition the variability of our outcome variable <span class="math inline">\(x\)</span> in both the between-subjects and the within subjects-case. In a mixed ANOVA, we do both of these things. It is almost like running two separate ANOVAs.</p>
<p>To test <strong>between-subjects effects</strong>, we first compute each subjects average score across all within-conditions. We then compute the sums of squares for all effects and the respective error term in the same fashion as we would in a pure between-subjects design.</p>
<p>In order to test the effects of main effects or interactions of within-subjects effects and within-between-interactions, we focus solely on the variability within participants. We partition this variability just as we would if this were a pure within-subjects design. That is, <strong>we treat a within-between-interaction as if it was just another within-subjects factor</strong>.</p>
<p>When computing mean squares from the different sums of squares, we need to consider that we have two error terms. For between-effects, this is the variability within the different between-subjects conditions (collapsed across all levels of our within-subjects factors). For within-effects, it is that part of the variability within participants that we cannot account for with our within-effects and within-between-interactions. You will, thus, see two different mean squared errors (MSE) in the ANOVA output of a mixed ANOVA.</p>
<section id="running-mixed-anovas-in-r" class="level3">
<h3 class="anchored" data-anchor-id="running-mixed-anovas-in-r">Running mixed ANOVAs in R</h3>
<p>Running mixed ANOVAs in R is easy. All we need to do feed the <strong><code>aov_ez()</code></strong> function both the <code>between</code> and <code>within</code> arguments. As always, we first need some data for the mixed ANOVA. Let’s say we ran study testing an intervention using a <span class="math inline">\(2 \times 2\)</span> design with experimental condition (treatment vs.&nbsp;control) as a between-subjects factor and measurement time (pre treatment vs.&nbsp;post treatment) as a within-subjects factor. Here is an excerpt of the data:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID      cond time score
1  1 treatment  pre     4
2  2 treatment  pre     7
3  3 treatment  pre     7
4  4 treatment  pre     4
5  5 treatment  pre     7
6  6 treatment  pre     7</code></pre>
</div>
</div>
<p>Here is what the data looks like if we were to visualise it:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference6_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now that we have some data, we can actually run the mixed ANOVA. Here is the syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run a mixed 2 by 2 ANOVA and save it as an object</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>aov2 <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">between =</span> <span class="st">'cond'</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">within =</span> <span class="st">'time'</span>, <span class="at">dv =</span> <span class="st">'score'</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> df2)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># show the results in the console</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>aov2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once we run that code, we will get the following console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Contrasts set to contr.sum for the following variables: cond</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: score
     Effect    df  MSE         F   ges p.value
1      cond 1, 78 1.26      0.04 &lt;.001    .833
2      time 1, 78 0.56 12.12 ***  .046   &lt;.001
3 cond:time 1, 78 0.56    6.96 *  .027    .010
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, the output contains three effects, the two main effects and the within-between interaction. Note also that the between-subjects effect of “condition” uses a different error mean squares (based on the variability between subjects) that the within-subjects effect os “time” and the interaction term (which is based on the within-subject variability).</p>
</section>
<section id="disentangling-effects-in-mixed-anovas" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-effects-in-mixed-anovas">Disentangling effects in mixed ANOVAs</h3>
<p>Let’s quickly think back on the two-factorial between-subjects ANOVA. Remember what we said about disentangling effects when ANVOAs have more than one factor? The bottom line was: which effects we are going to interpret and, thus, need to disentangle, depends on the interaction effect. We should only interpret significant main effects if a) there is no evidence of an interaction, or b) the interaction is ordinal.</p>
<p>If we have a significant interaction, we first need to find out how exactly it looks. One way to go about this is using pairwise comparisons on all cells. However, this can get messy with large designs simply because the number of possible pairwise comparisons increases exponentially with the number of a design’s cells. Alternatively, we could manually specify post-hoc contrasts to get exactly those contrasts we are interested in. Of course, this can be tedious with large designs, and it is somewhat error prone if we need to enter large numbers of vectors containing contrast weights.</p>
<p>The good news is that there is another elegant way to run analyses of the simple effects behind an interaction, namely providing the <strong><code>emmeans()</code></strong> function with a <strong>formula</strong> when defining the <code>specs</code> argument.</p>
<p>Generally speaking, when we use a formula to specify <code>specs</code> we are telling the function to run certain contrasts on one variable (or even more than one) for each level of another (or for each combination of several others). Here is what the syntax looks like in the case of simple effects:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run pairwise comparisons for the between-factor </span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 'cond' for each level of the within-factor 'time'</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="sc">~</span> cond <span class="sc">|</span> time,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can read the formula we fed the <strong><code>emmeans()</code></strong> to define its <code>spec</code> argument as follows: run contrasts on “cond” for each level of “time”. Which contrasts to run is, once again, specified using the <code>contr</code> argument, in our case pairwise comparisons.</p>
<p>Let’s have a look at the console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>time = pre:
 contrast            estimate    SE df t.ratio p.value
 treatment - control   -0.275 0.242 78  -1.136  0.2593

time = post:
 contrast            estimate    SE df t.ratio p.value
 treatment - control    0.350 0.180 78   1.944  0.0555</code></pre>
</div>
</div>
</div>
<p>As we can see, the output tells us which effect the experimental condition (treatment vs.&nbsp;control) has for each time point (pre. vs.&nbsp;post). Here, we can only confirm an effect after the treatment (post), but our data do not allow conclusions before treatment (pre).</p>
<p>In order to get the full picture of the interaction, we also need to inspect the effect of time by condition. To this end, we simply switch the two variables in our formula specification of <code>specs</code> (see syntax below).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run pairwise comparisons for the between-factor </span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 'cond' for each level of the within-factor 'time'</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="sc">~</span> time <span class="sc">|</span> cond,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>cond = treatment:
 contrast   estimate    SE df t.ratio p.value
 pre - post   -0.725 0.168 78  -4.327  &lt;.0001

cond = control:
 contrast   estimate    SE df t.ratio p.value
 pre - post   -0.100 0.168 78  -0.597  0.5523</code></pre>
</div>
</div>
</div>
<p>As we can see, there is only an effect of the time at which we measure the dependent variable when there is a treatment in between (which we would probably expect in this kind of research design). We cannot say, however, whether there is any change in the dependent variable for participants in the control group since the respective simple effect is not statistically significant.</p>
<div class="alert alert-danger">
<p><strong>Caveat</strong>: Doing post-hoc contrasts in this fashion imposes a restriction on the adjustment of <span class="math inline">\(p\)</span>-values for multiple comparisons. R will not adjust for all tests, but for all comparisons within a level of the grouping variable.</p>
</div>
<p>In our example, we would not interpret the main effect of “time” because we have a semi-disordinal interaction. That is, we cannot say that “time” has a general impact on the dependent variable, and we would also not claim that experimental condition has a general effect. Whether they have an effect seems to depend on the level of the respective other variable (thus, the significant within-between interaction in the ANOVA).</p>
<p>In addition, since we have only two factor levels for “time”, there would be no need to disentangle the effects (we could just look at the means to infer the direction of the effect). If we were interested in disentangling a main effect, however, we could do it using <strong><code>emmeans()</code></strong> just like we did it in the case of the two-factorial between-subjects ANOVA.</p>
<p>In order to disentangle a main effect, we need to run pairwise comparisons on its <strong>marginal means</strong> (i.e., the means when collapsing across the levels of other factors). We can do so by feeding the <strong><code>emmeans()</code></strong> function only the factor of interest when defining <code>specs</code> (omitting the other factors).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># disentangle the main effect of time</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> aov2, <span class="at">specs =</span> <span class="st">'time'</span>,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is wehat appears in the console once we run that code:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 time emmean    SE df lower.CL upper.CL
 pre    5.84 0.121 78     5.60     6.08
 post   6.25 0.090 78     6.07     6.43

Results are averaged over the levels of: cond 
Confidence level used: 0.95 

$contrasts
 contrast   estimate    SE df t.ratio p.value
 pre - post   -0.412 0.118 78  -3.482  0.0008

Results are averaged over the levels of: cond </code></pre>
</div>
</div>
</div>
<p>When looking at the effect of time, the analysis reveals a difference between the two marginal means pre and post treatment (this is equivalent to the main effect of time in the ANOVA since we have only got two factor levels). Conveniently, the output also reminds us that these are marginal means by stating that results are averaged across the levels of our other factor “cond”.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>