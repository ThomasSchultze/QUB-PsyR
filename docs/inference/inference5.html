<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.258">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUB-PsyR - The two-factorial ANOVA</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/QUBlogoWsmall.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">QUB-PsyR</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="../intro/intro1.html">
 <span class="dropdown-text">R and RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro2.html">
 <span class="dropdown-text">Running Code in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro3.html">
 <span class="dropdown-text">Objects and Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro4.html">
 <span class="dropdown-text">Data Frames and Lists</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../intro/intro5.html">
 <span class="dropdown-text">Saving and Loading Data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-working-with-r-objects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Working with R Objects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-working-with-r-objects">    
        <li>
    <a class="dropdown-item" href="../working/working1.html">
 <span class="dropdown-text">Binary Operators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working2.html">
 <span class="dropdown-text">Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working3.html">
 <span class="dropdown-text">Numerical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working4.html">
 <span class="dropdown-text">Logical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../working/working5.html">
 <span class="dropdown-text">R Packages</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-inference" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Inference</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-statistical-inference">    
        <li>
    <a class="dropdown-item" href="../inference/inference0.html">
 <span class="dropdown-text">A Primer on Statistical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference1.html">
 <span class="dropdown-text">The t-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference2.html">
 <span class="dropdown-text">The Chi²-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference3.html">
 <span class="dropdown-text">Correlations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference4.html">
 <span class="dropdown-text">One-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference5.html">
 <span class="dropdown-text">Two-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference6.html">
 <span class="dropdown-text">Repeated measures and mixed ANOVAs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference7.html">
 <span class="dropdown-text">Simple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference8.html">
 <span class="dropdown-text">Multiple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../inference/inference9.html">
 <span class="dropdown-text">Multi-level models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-data-visualisation" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Data Visualisation</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-data-visualisation">    
        <li>
    <a class="dropdown-item" href="../graphs/graphs0.html">
 <span class="dropdown-text">Preface</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs1.html">
 <span class="dropdown-text">Histograms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs2.html">
 <span class="dropdown-text">Scatterplots</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../graphs/graphs3.html">
 <span class="dropdown-text">Violin plots</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-data-wrangling" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Data Wrangling</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-data-wrangling">    
        <li>
    <a class="dropdown-item" href="../wrangling/wrangling0.html">
 <span class="dropdown-text">Preface</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../wrangling/wrangling1.html">
 <span class="dropdown-text">Extracting rows and columns</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The two-factorial ANOVA</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The two-factorial analysis of variance (ANOVA) in an extension of the one-factorial ANOVA. It allows us to test how the mean of a continuous variable differs as a function of two categorical variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. In a two-factorial ANOVA, we can not only test for the independent effects of the two variables on the outcome, but also a possible interaction of the two variables <span class="math inline">\(A \times B\)</span>. Here, interaction means that the magnitude and/or direction of the effect of one of the variables depends on the level of the second variable.</p>
<p>A two-factorial design requires that the two variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are “crossed”. That means that each level of the first factor <span class="math inline">\(A\)</span> must be combined with each level of the second second factor <span class="math inline">\(B\)</span>. If <span class="math inline">\(A\)</span> has three levels and <span class="math inline">\(B\)</span> has two levels, our design has a total of 6 cells, and we would refer to it as a <span class="math inline">\(3 \times 2\)</span>-design.</p>
<p>If we ensure, in addition, that all cells of our design have the same sample size, we call our design <strong>orthogonal</strong>. Orthogonality is not required for running a two-factorial ANOVA, but it comes with an advantage: equal sample sizes make the ANOVA robust against violating the assumption of equal variances.</p>
<section id="general-logic-of-the-two-factorial-anova" class="level2">
<h2 class="anchored" data-anchor-id="general-logic-of-the-two-factorial-anova">General logic of the two-factorial ANOVA</h2>
<p>The model underlying the two-factorial ANOVA looks like this:</p>
<p><span class="math display">\[\mu_{jk} = \mu+\alpha_j+\beta_k+\gamma_{jk}\]</span> Here, <span class="math inline">\(\mu_{jk}\)</span> is the true mean or a combination of the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span> and the <span class="math inline">\(kth\)</span> level of factor <span class="math inline">\(B\)</span>, <span class="math inline">\(\mu\)</span> is the true grand mean (i.e., the population mean across all groups), <span class="math inline">\(\alpha_j\)</span> is the true effect of the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span>, <span class="math inline">\(\beta_k\)</span> is the true effect of the <span class="math inline">\(k\)</span>th level of factor <span class="math inline">\(B\)</span>, and <span class="math inline">\(\gamma_{jk}\)</span> is the true effect of combining the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span> with the <span class="math inline">\(k\)</span>th level of <span class="math inline">\(B\)</span> that goes beyond the independent contributions of the two factors (<span class="math inline">\(\alpha_j\)</span> and <span class="math inline">\(\beta_k\)</span>).</p>
<p>Just as with the one-factorial ANOVA, its two-factorial cousin partitions the variance of the outcome variable <span class="math inline">\(\sigma_x^2\)</span> into signal and noise. The signal is the variance that stems from differences between groups, and the noise is the variance that is due to differences within the groups. Here, too, we can simplify the partition of variances by partitioning the sums of squares instead. As with the one-factorial ANOVA, we can state that:</p>
<p><span class="math display">\[SS_{total} = SS_{between} + SS_{within}\]</span></p>
<p>The difference to the one-factorial ANVOA is that we can now partition the signal (the <span class="math inline">\(SS_{between}\)</span>) even further. Specifically, we can partition the variability between groups into variability that is due to the first factor <span class="math inline">\(A\)</span>, variability that is due to the second factor <span class="math inline">\(B\)</span>, and variability that results from the interaction of the two factors <span class="math inline">\(A \times B\)</span>. We can state this formally as follows:</p>
<p><span class="math display">\[SS_{between} = SS_A + SS_B + SS_{A \times B}\]</span></p>
<p>Let’s have a closer look at the sums of squares using a simplest possible example, namely the <span class="math inline">\(2 \times 2\)</span>-design, in which factor <span class="math inline">\(A\)</span> has <span class="math inline">\(J = 2\)</span> levels, and factor <span class="math inline">\(B\)</span> also has <span class="math inline">\(K=2\)</span> levels. We can think of this design as a squares divided into four parts (see below):</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference5_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In each of the four cells of this <span class="math inline">\(2 \times 2\)</span> design, there are <span class="math inline">\(n_{jk}\)</span> many observations of the outcome variable <span class="math inline">\(x\)</span>, where <span class="math inline">\(n_{jk}\)</span> is the sample size in the cell formed by the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span> and the <span class="math inline">\(k\)</span>th level of <span class="math inline">\(B\)</span>. We denote individual observations as <span class="math inline">\(x_{ijk}\)</span>, which refers to the <span class="math inline">\(i\)</span>th observation in the cell formed b the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span> and the <span class="math inline">\(k\)</span>th level of <span class="math inline">\(B\)</span>.</p>
<p>When we want to partition the sum of squares in a two-factorial design, we first need to compute the total sum of squares. We do so, by collapsing across all cells of our design and summing the squared deviations of all observations from the grand mean <span class="math inline">\(\bar{x}\)</span> (i.e., the mean computed across all observations irrespective of which cell they stem from). We can formalise this as:</p>
<p><span class="math display">\[SS_{total} = \sum_{j=1}^{J} \sum_{k=1}^{K} \sum_{i=1}^{n_{jk}} (x_{ijk}-\bar{x})^2\]</span> The next step is computing <span class="math inline">\(SS_{between}\)</span> by pretending that there is no variance within groups. Computing the <span class="math inline">\(SS_{between}\)</span> works similar to the one-factorial ANOVA. That means, we replace each observation <span class="math inline">\(x_{ijk}\)</span> with the mean of its cell <span class="math inline">\(\bar{x}_{jk}\)</span> before computing the sum of the squared deviations from the grand mean <span class="math inline">\(\bar{x}_{jk}\)</span>.</p>
<p><span class="math display">\[SS_{between} = \sum_{j=1}^{J} \sum_{k=1}^{K} n_{jk} \times (\bar{x}_{jk} - \bar{x})^2\]</span> Computing the <span class="math inline">\(SS_{within}\)</span> is also similar to the one-factorial ANOVA. We pretend that there is no variation between groups by replacing the grand mean <span class="math inline">\(\bar{x}\)</span> with the cell means <span class="math inline">\(\bar{x}_{jk}\)</span> in the formula for the total sum of squares.</p>
<p><span class="math display">\[SS_{within} = \sum_{j=1}^{J} \sum_{k=1}^{K} \sum_{i = 1}^{n_{jk}}  (x_{ijk} - \bar{x}_{jk})\]</span></p>
<p>So far, so good. We have now partitioned <span class="math inline">\(SS_{total}\)</span> into the <span class="math inline">\(SS_{between}\)</span> and the <span class="math inline">\(SS_{within}\)</span>. However, since we have a <span class="math inline">\(2 \times 2\)</span>-design, we are not merely interested in <em>whether</em> there is substantial variation between the groups, but also <em>where</em> this variation originates. Thus, we need to partition the sums of squares further.</p>
<p>We first compute <span class="math inline">\(SS_A\)</span>, that is, the variation that is solely due to differences in factor <span class="math inline">\(A\)</span>. We do so by pretending that a) there is no factor <span class="math inline">\(B\)</span>, and b) there is no variation within cells. The latter is necessary because <span class="math inline">\(SS_A\)</span> is part of <span class="math inline">\(SS_{between}\)</span>. The good thing is that we already know how to do it, namely by replacing individual observations with a mean score. But how do we pretend that there is no factor <span class="math inline">\(B\)</span>? Effectively, we collapse across all levels of <span class="math inline">\(B\)</span> and combine them into one big cell for each level of <span class="math inline">\(A\)</span>. Here is what our <span class="math inline">\(2 \times 2\)</span>-design would look like in our minds now:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference5_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We now denote the individual observations as <span class="math inline">\(x_{ij\cdot}\)</span>. The little dot reminds us that there was originally another factor <span class="math inline">\(B\)</span> across which we have now collapsed the cells of our design. To obtain <span class="math inline">\(SS_A\)</span>, we now need to replace all individual observations with their respective cell means respective cell means <span class="math inline">\(\bar{x}_{j\cdot}\)</span> and then compute the sum of their squared deviations from the grand mean <span class="math inline">\(\bar{x}\)</span> .</p>
<p><span class="math display">\[SS_A = \sum_{j=1}^{J} n_{j\cdot}(\bar{x}_{j\cdot}-\bar{x})^2   \]</span> Here, <span class="math inline">\(n_{j\cdot}\)</span> refers to the number of observations for the <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(A\)</span> (irrespective of the level of factor <span class="math inline">\(B\)</span>).</p>
<p>We can now compute the <span class="math inline">\(SS_B\)</span> in a similar fashion, namely by pretending that a) there is no factor <span class="math inline">\(A\)</span>, and b) there is no variation within cells. Our imagined design now looks like this:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference5_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We note denote individual observations as <span class="math inline">\(x_{i\cdot k}\)</span> to emphasize that we do not consider which level of <span class="math inline">\(A\)</span> an observation stems from. Accordingly, the cell means are now denoted as <span class="math inline">\(\bar{x}_{\cdot k}\)</span>. The <span class="math inline">\(SS_B\)</span> are formally defined as:</p>
<p><span class="math display">\[SS_B = \sum_{k=1}^{K} n_{\cdot k}(\bar{x}_{\cdot k}-\bar{x})^2   \]</span></p>
<p>Finally, we need to compute the variability that is due to the interaction of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The simplest way to do so is to subtract the newly computed <span class="math inline">\(SS_A\)</span> and <span class="math inline">\(SS_B\)</span> from <span class="math inline">\(SS_{between}\)</span>:</p>
<p><span class="math inline">\(SS_{A \times B} = SS_{between} - SS_A - SS_B\)</span></p>
<p>If we run a two-factorial ANOVA, we no longer need the <span class="math inline">\(SS_{between}\)</span> because its parts, <span class="math inline">\(SS_A\)</span>, <span class="math inline">\(SS_B\)</span>, and <span class="math inline">\(SS_{a \times B}\)</span> contain all the variation between groups. The next step is to test each component of the between-group variation for statistical significance. The logic is similar to that of the one-factorial ANOVA, that is, we test for significant using an <span class="math inline">\(F\)</span>-statistic.</p>
<p>Since we have three possible sources of between-group variability, we will run three tests: one for the main effect of factor <span class="math inline">\(A\)</span>, one for the main effect of factor <span class="math inline">\(B\)</span>, and one for the interaction effect <span class="math inline">\(a \times B\)</span>. For each of these tests, we need to compute the mean squares of the effect we are interested in and divide it by the <span class="math inline">\(MS_within\)</span>. We can obtain <span class="math inline">\(MS_A\)</span>, <span class="math inline">\(MS_B\)</span>, <span class="math inline">\(MS_{A \times B}\)</span>, and <span class="math inline">\(MS_within\)</span> by dividing the respective sum of squares by its degrees of freedom (see below).</p>
<p><span class="math display">\[MS_A = \frac{SS_A}{J-1}\]</span> <span class="math display">\[MS_B = \frac{SS_B}{K-1}\]</span></p>
<p><span class="math display">\[MS_{A\times B} = \frac{SS_{A\times B}}{(J-1)(K-1)}\]</span> <span class="math display">\[MS_{within} = \frac{SS_{within}}{N-J\times K}\]</span></p>
<section id="the-main-effect-of-factor-a" class="level4">
<h4 class="anchored" data-anchor-id="the-main-effect-of-factor-a">The main effect of factor A</h4>
<p>Let’s first look at the test for the main effect of <span class="math inline">\(A\)</span>. The <span class="math inline">\(F\)</span>-statistic looks as follows:</p>
<p><span class="math display">\[\frac{MS_A}{MS_{wihtin}} \sim F_{J-1;N-J\times K}\]</span> We use it to test the following hypotheses:</p>
<p><span class="math inline">\(H_{0_A}: \alpha_j = 0 \quad \forall j\)</span></p>
<p><span class="math inline">\(H_{1_A}: \lnot H_{0_A}\)</span></p>
<p>Remember that <span class="math inline">\(\alpha_j\)</span> is the true effect of the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span>, which means that:</p>
<p><span class="math inline">\(\mu_{j\cdot} = \mu+\alpha_j\)</span></p>
<p>In other words, when we add <span class="math inline">\(\alpha_j\)</span> to the overall population mean <span class="math inline">\(\mu\)</span> (the true value of <span class="math inline">\(\bar{x}\)</span>), we obtain the expectancy of the mean for the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span> (collapsed over all levels of <span class="math inline">\(B\)</span>).</p>
</section>
<section id="the-main-effect-of-factor-b" class="level4">
<h4 class="anchored" data-anchor-id="the-main-effect-of-factor-b">The main effect of factor B</h4>
<p>Regarding the main effect of <span class="math inline">\(B\)</span>, this is what the <span class="math inline">\(F\)</span>-statistic look:</p>
<p><span class="math display">\[\frac{MS_B}{MS_{wihtin}} \sim F_{K-1;N-J\times K}\]</span> The corresponding hypotheses are:</p>
<p><span class="math inline">\(H_{0_B}: \beta_k = 0 \quad \forall k\)</span></p>
<p><span class="math inline">\(H_{1_B}: \lnot H_{0_B}\)</span></p>
<p>Again, <span class="math inline">\(\beta_k\)</span> is the true effect of the <span class="math inline">\(k\)</span>th level of B. We can state that:</p>
<p><span class="math inline">\(\mu_{\cdot k} = \mu + \beta_k\)</span></p>
<p>This means that adding <span class="math inline">\(\beta_k\)</span> to the true population mean <span class="math inline">\(\mu\)</span> will result in the expected mean of the <span class="math inline">\(k\)</span>th level of factor <span class="math inline">\(B\)</span> (collapsed across all levels of <span class="math inline">\(A\)</span>).</p>
</section>
<section id="the-interaction-of-a-and-b" class="level4">
<h4 class="anchored" data-anchor-id="the-interaction-of-a-and-b">The interaction of A and B</h4>
<p>The <span class="math inline">\(F\)</span>-statistic for the interaction effect <span class="math inline">\(A \times B\)</span> is defined as follows:</p>
<p><span class="math display">\[\frac{MS_{A \times B}}{MS_{wihtin}} \sim F_{(J-1)(K-1);N-J\times K}\]</span></p>
<p>We use this <span class="math inline">\(F\)</span>-statistic to test the final hypothesis, which is very similar to the main effect hypotheses:</p>
<p><span class="math inline">\(H_{0_{A \times B}}: \gamma_{A \times B} = 0 \quad \forall j,k\)</span></p>
<p><span class="math inline">\(H_{1_{A \times B}}: \lnot H_{0_{A\times B}}\)</span></p>
<p>As mentioned above, <span class="math inline">\(\gamma_{jk}\)</span> is the effect that combining the <span class="math inline">\(j\)</span>th level of <span class="math inline">\(A\)</span> and the <span class="math inline">\(k\)</span>th level of <span class="math inline">\(B\)</span> has on the population mean <span class="math inline">\(\mu\)</span> <strong>beyond</strong> the respective main effects <span class="math inline">\(\alpha_j\)</span> and <span class="math inline">\(\beta_k\)</span>. We define <span class="math inline">\(\gamma_{A \times B}\)</span> such that:</p>
<p><span class="math display">\[\mu_{jk} = \mu + \alpha_j + \beta_k + \gamma_{jk} = 0\]</span></p>
<p>This means that when we look at individual cells of our design instead of collapsing across rows or columns, we can obtain the respective true cell mean <span class="math inline">\(\mu_{jk}\)</span> by taking the true grand mean <span class="math inline">\(\mu\)</span> and adding not only <span class="math inline">\(\alpha_j\)</span> and <span class="math inline">\(\beta_k\)</span> but also <span class="math inline">\(\gamma_{jk}\)</span>.</p>
</section>
</section>
<section id="running-a-two-factorial-anova-in-r" class="level2">
<h2 class="anchored" data-anchor-id="running-a-two-factorial-anova-in-r">Running a two-factorial ANOVA in R</h2>
<p>When we want to run a two-factorial ANOVA in R, we can use the same package and function we used for the one-factorial case. That is, we use the <em>aov_ez</em> function of the package <em>afex</em>. Before we can run the analysis, we first need data from a two-factorial design.</p>
<p>Let’s say, we have data from an experimental <span class="math inline">\(2 \times 2\)</span>-design in which we manipulated two factors: job <em>demands</em> (low vs.&nbsp;high) and <em>autonomy</em> (low. vs.&nbsp;high). The dependent variable is the experienced level of job <em>stress</em>. Let’s further assume that we have gathered data from 50 participants in each of the four cells of our design and stored it in a data frame called “my_df”. Here is an except of the data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID demands control stress
1  1     low     low    112
2  2     low    high     79
3  3    high     low    134
4  4    high    high     76
5  5     low     low    114
6  6     low    high    129</code></pre>
</div>
</div>
<p>The difference to a one-factorial ANOVA is that we need to feed the <em>aov_ez</em> function a vector containing two variable names as its <em>between</em> argument (in the one-factorial case it was a single character value). Here is what the syntax looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load library afex</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(afex)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># run a two-factorial ANOVA with demands and control as the </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># independent variables and stress as the dependent variable</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>my_ANOVA <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">between =</span> <span class="fu">c</span>(<span class="st">'demands'</span>, <span class="st">'control'</span>), </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">dv =</span> <span class="st">'stress'</span>, <span class="at">data =</span> my_df)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># display the results of the ANOVA</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>my_ANOVA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running this code will create an ANOVA object called “my_ANOVA” in the environment and then display the results of the analysis in the console. Here is what the output looks like:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Contrasts set to contr.sum for the following variables: demands, control</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: stress
           Effect     df    MSE         F  ges p.value
1         demands 1, 196 455.82 43.92 *** .183   &lt;.001
2         control 1, 196 455.82 20.02 *** .093   &lt;.001
3 demands:control 1, 196 455.82    4.15 * .021    .043
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, the output is an ANOVA table. R tells us that the tests are based on type-3 sums of squares and tells us what the outcome variable was in our analysis (stress). The table itself contains three effects: a main effect of demands (the first variable we entered as a between-subjects factor), a main effect of control (the second between-subjects factor), and the interaction of the two variables denoted by “demands:control” (in R, the colon often indicates an interaction effect).</p>
<p>For each effect, R displays the numerator and denominator degrees of freedom, the <span class="math inline">\(MS_within\)</span> (they are necessarily equal for all three effects), the <span class="math inline">\(F\)</span>-value, an estimate of the effect size <span class="math inline">\(\eta^2\)</span>, and the <span class="math inline">\(p\)</span>-value. In our example, all three effects are statistically significant. Statistically speaking, we can now reject all of the Null hypotheses, that is, we would conclude that the level of demands has an effect on stress, that the level of control has an effect on stress, and that there is an interaction of the two variables.</p>
</section>
<section id="disentangling-effects-in-a-two-factorial-anova" class="level2">
<h2 class="anchored" data-anchor-id="disentangling-effects-in-a-two-factorial-anova">Disentangling effects in a two-factorial ANOVA</h2>
<p>Similar to the one-factorial ANOVA, the tests we run in a two-factorial ANOVA are unspecific in the sense that they do not tell us which means differ from one another. However, disentangling effect in two-factorial ANOVAs is non-trivial. Which effects we need to disentangle and how we go about it depends on a) whether there is a significant interaction and b) how many levels our factors have.</p>
<section id="interactions-and-the-interpretation-of-main-effects" class="level3">
<h3 class="anchored" data-anchor-id="interactions-and-the-interpretation-of-main-effects">Interactions and the interpretation of main effects</h3>
<p>Let’s first consider what difference it makes whether there is a significant interaction. In order to do that, we first need to consider what a main effect is in a two-factor ANOVA. Here, we must distinguish between the statistical main effect as returned by the ANOVA and an actual main effect in the psychological sense. <strong>We speak of an actual main effect if the order of the levels of one factor holds across all levels of the other factor.</strong> For example, in a <span class="math inline">\(2 \times 2\)</span>-design, we would speak of a main effect of factor <span class="math inline">\(A\)</span> if the first level of <span class="math inline">\(A\)</span> was associated with higher (or lower) scores than its second level, irrespective of whether we look at the first or the second level of factor <span class="math inline">\(B\)</span>.</p>
<p>Here is the problem: because the statistical main effect of a factor in an ANOVA is computed by collapsing across the levels of the other factor, there are different patterns that produce a significant mean difference but do not satisfy the condition described in the previous paragraph. When can those pattern occur? The answer is: when there is an interaction of the two factors.</p>
<p>What does this mean for us? First for the easy case in which there is no interaction. If the interaction effect is not significant, we cannot accept <span class="math inline">\(H_{1_{A\times B}}\)</span>. That means we retain <span class="math inline">\(H_{0_{A\times B}}\)</span> for now (without believing that it is true because the non-significant finding is uninformative). Retaining <span class="math inline">\(H_{0_{A\times B}}\)</span> implies that if there are any significant main effects in the ANOVA, we can interpret them as is and disentangle them similar to effects in a one-factorial ANOVA.</p>
<p>Now let’s assume that we found a significant interaction effect. This is where things become difficult. Let’s look at a few graphs to understand this issue better. All of the situations below constitute cases where an ANOVA would show a significant interaction an two significant main effects However, not all of these situations permit us to interpret the data in terms of actual main effects.</p>
<p><img src="images/inference/2x2aov_1.png" class="img-fluid"> In this first case, we can see that there is an interaction because the lines to not run parallel. We can also see that there are main effects of factors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The main effect of factor <span class="math inline">\(A\)</span> becomes evident from the marginal means <span class="math inline">\(\bar{x}_{j\cdot}\)</span>, which we can derive by averaging across the blue and orange points for each level of <span class="math inline">\(A\)</span>. As we can see from the right side of the graph, there is a considerable distance between the two means <span class="math inline">\(\bar{x}_{1\cdot}\)</span> and <span class="math inline">\(\bar{x}_{2\cdot}\)</span>. This difference is the main effect of factor <span class="math inline">\(A\)</span> in the <span class="math inline">\(2\times 2\)</span> ANOVA. We can also see from the left side of the graph that the two marginal means <span class="math inline">\(\bar{x}_{\cdot 1}\)</span> and <span class="math inline">\(\bar{x}_{\cdot 2}\)</span> differ (we can obtain them by taking the averages of the same-coloured points). This is the main effect of factor <span class="math inline">\(B\)</span>.</p>
<p><strong>Importantly</strong>, despite the interaction effect, the order of the factor levels does not change. We call this an <strong>ordinal interaction</strong>. Irrespective of the level of factor <span class="math inline">\(B\)</span>, we obtain higher values when the level of factor <span class="math inline">\(A\)</span> is <span class="math inline">\(j=2\)</span> instead of <span class="math inline">\(j=1\)</span>. Similarly, irrespective of the level of factor <span class="math inline">\(A\)</span>, values are higher when factor <span class="math inline">\(B\)</span>’s level is <span class="math inline">\(k=2\)</span> instead of <span class="math inline">\(k=1\)</span>. Therefore, we can interpret the statistical main effects as actual main effects and state that the level of our dependent variables is <strong>generally higher</strong> for one level of factor <span class="math inline">\(A\)</span> than for the other. Similarly, we can state that the values are <strong>generally higher</strong> for on level of factor <span class="math inline">\(B\)</span> than for the other.</p>
<p>So far, so good. Now lets’ look at the next case.</p>
<p><img src="images/inference/2x2aov_2.png" class="img-fluid"></p>
<p>In this scenario, an ANOVA would also show an interaction effect (non-parallel lines) and two main effects (evidenced by differences between the marginal means). The difference to the previous scenario is the effect of factor <span class="math inline">\(A\)</span> when we fix factor <span class="math inline">\(B\)</span> at level <span class="math inline">\(k=2\)</span>. This effect is a flat line. Although the values differ slightly, the pattern for factor <span class="math inline">\(B\)</span> remains similar with <span class="math inline">\(k=2\)</span> yielding higher values of the dependent variable than <span class="math inline">\(k=1\)</span> irrespective of the level of factor <span class="math inline">\(A\)</span>. We call this type of interaction <strong>semi-disordinal</strong> because order is only maintained for one factor and not inverted for the other. How does this change our interpretation of the main effect?</p>
<p>We would still state that the values are <strong>generally higher</strong> for on level of factor <span class="math inline">\(B\)</span> than for the other. However, we cannot state the same for factor <span class="math inline">\(A\)</span>. As we can see, whether one level of <span class="math inline">\(A\)</span> is associated with higher levels of the dependent variable in <strong>conditional</strong> on the level of factor <span class="math inline">\(B\)</span>. We see an effect fo factor <span class="math inline">\(A\)</span> when we fix <span class="math inline">\(B\)</span> at level <span class="math inline">\(k=1\)</span>, but if we fix it at <span class="math inline">\(k=2\)</span> instead, there is no longer a difference between the two levels of factor <span class="math inline">\(A\)</span>. Therefore, we cannot interpret the data as showing an actual main effect of factor <span class="math inline">\(A\)</span> even though this effect may show up in the ANOVA.</p>
<p>Let’s now look at the third scenario.</p>
<p><img src="images/inference/2x2aov_3.png" class="img-fluid"></p>
<p>As in the previous scenarios, an ANOVA would show a significant interaction (non-parallel lines) and two main effects (see the marginal means). This time, <strong>both factor’s main effects are conditional</strong> on the level of the other factor. Factor <span class="math inline">\(A\)</span> only has an effect on the dependent variable if we fix factor <span class="math inline">\(B\)</span> at level <span class="math inline">\(k=1\)</span>, and factor B only has an effect when factor <span class="math inline">\(A\)</span>’s level is <span class="math inline">\(j=2\)</span>. In this case, we cannot interpret either of the two significant main effects in the ANOVA as actual main effect. Note that although order is maintained nor neither factor, we would still consider this a <strong>semi-disordinal</strong> interaction because there is no inversion of the factor’s order.</p>
<p>Now for the grand finale:</p>
<p><img src="images/inference/2x2aov_4.png" class="img-fluid"> Again, an ANOVA would tell us that there is a significant interaction and two significant main effects. However, as we can see, the notion of main effects is maximally misleading here. If we look at factor <span class="math inline">\(A\)</span>, we will see that its effect can be positive (in the sense that it leads to higher levels of the dependent variable), or it can be negative. Whether the effect is positive or negative depends on the level of factor <span class="math inline">\(B\)</span>. The same is true for factor <span class="math inline">\(B\)</span>. Whether this factor has a positive or negative effect on the level of the dependent variable depends on the level of factor <span class="math inline">\(A\)</span>. We call this a <strong>disordinal</strong> interaction because the order of factor levels (in terms of which has the higher values of the dependent variable) reverses for each factor depending on the levels of the other factor. This means that - similar to the previous scenario - we cannot interpret the statistical main effects to be actual main effects.</p>
<div class="alert alert-danger">
<p>The bottom line here is that we should only bother disentangling <strong>actual main effects</strong> and not any main effect that is statistically significant in a 2-factorial ANOVA.</p>
<p>This means that we should disentangle main effects only if there is no evidence of an interaction or if the interaction is ordinal.</p>
</div>
</section>
<section id="disentangling-main-effects" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-main-effects">Disentangling main effects</h3>
<p>Let’s first consider the disentangling of main effects (assuming that there is no significant interaction or an ordinal interaction). When a factor has only two levels, the case is clear, because the difference must be between those two levels.</p>
<p>If we have three or more levels, we need to disentangle the main effect in the same way we disentangled them in a one-factorial case. That means we can run pairwise comparisons or custom contrasts on that factor’s marginal means (i.e., collapsing across all levels of the other factor) using the <em>emmeans</em> function from the package <em>emmeans</em>.</p>
<p>In our example from far above, the factor “demands” has only two levels, but we can still use the data to show how the syntax and output would look like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load library emmeans</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># pairwise comparisons on the demands factor with Bonferroni correction</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> my_ANOVA, <span class="at">specs =</span> <span class="st">'demands'</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="st">'pairwise'</span>, <span class="at">adjust =</span> <span class="st">'bonferroni'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running the code above will yield the following console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>NOTE: Results may be misleading due to involvement in interactions</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 demands emmean   SE  df lower.CL upper.CL
 low       99.9 2.13 196     95.7      104
 high     119.9 2.13 196    115.7      124

Results are averaged over the levels of: control 
Confidence level used: 0.95 

$contrasts
 contrast   estimate   SE  df t.ratio p.value
 low - high      -20 3.02 196  -6.627  &lt;.0001

Results are averaged over the levels of: control </code></pre>
</div>
</div>
</div>
<p>Similar to the one-factorial case, the output will consist of two tables, with the second of them containing the desired information. In this case, we have only one entry here because the factor “demands” has only two levels (however, the logic of the post-hoc comparisons would not differ from the one-factorial case had we more than two levels).</p>
<p>There are two few things worth noting: First, when we feed the the <em>emmeans</em> a single variable as its <em>specs</em> argument, the output will contain a message stating that we collapsed across the other factor (in our case “control”). Thus, we know that we are talking about the marginal means of the “demands”. Second, when we call the <em>emmeans</em> function on a main effect in an ANOVA design with at least two factors, R will also return a message informing us that the results of our pairwise comparisons may be misleading due to involvement in potential interactions (we already know this by now).</p>
<p>Since we have two factors in a <span class="math inline">\(2 \times 2\)</span>-design, we need to consider that we may have two significant interpretable main effects. Generally speaking, we need to disentangle each significant main effect via its marginal means, granted that the interaction pattern (absent or ordinal interaction) permits it.</p>
</section>
<section id="disentangling-interactions" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-interactions">Disentangling interactions</h3>
<p>If a <span class="math inline">\(2 \times 2\)</span>-ANOVA reveals a significant interaction, we need to disentangle it. The reason is that - as we have seen from the different graphs above - there are various patterns that can produce an interaction effect, and we need to identify which one lead to the significant interaction. If the interaction is not significant, there is - of course - no need to disentangle the effect.</p>
<p>Before we try to answer the question how to disentangle an interaction effect, it helps to understand better what we actually test when testing an interaction effect. The best way to do that is to have a look at the contrasts underlying the tests of main effects and interaction in a <span class="math inline">\(2 \times 2\)</span> ANOVA. Note that we need to turn our two-factorial design into a one-factorial design for the purpose of defining the contrasts. The contrasts for the three tests look as follows:</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 18%">
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(j=1\)</span>; <span class="math inline">\(k=1\)</span></th>
<th><span class="math inline">\(j=2\)</span>, <span class="math inline">\(k=1\)</span></th>
<th><span class="math inline">\(j=1\)</span>; <span class="math inline">\(k=2\)</span></th>
<th><span class="math inline">\(j=2\)</span>; <span class="math inline">\(k=2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>main effect of <span class="math inline">\(A\)</span></td>
<td>1</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>main effect of <span class="math inline">\(B\)</span></td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>interaction effect</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Let’s digest this. For the main effect of <span class="math inline">\(A\)</span>, we can see that we compare the marginal means of its two levels because we average across the two levels of factor <span class="math inline">\(B\)</span>. Likewise, we can see that are comparing the marginal means of <span class="math inline">\(B\)</span> because we average across both levels of <span class="math inline">\(A\)</span>. Finally, and most importantly, we can see what the interaction contrast does. It tests whether the difference between the two levels of <span class="math inline">\(A\)</span> when <span class="math inline">\(B\)</span> is fixed at <span class="math inline">\(k=1\)</span> differs from the the same difference when <span class="math inline">\(B\)</span> is fixed at <span class="math inline">\(k=2\)</span>. This is equivalent to testing whether the difference between the two levels of <span class="math inline">\(B\)</span> when <span class="math inline">\(A\)</span> is fixed at <span class="math inline">\(j=1\)</span> differ from the difference between the two levels of <span class="math inline">\(B\)</span> when <span class="math inline">\(A\)</span> is fixed at <span class="math inline">\(j=2\)</span>.</p>
<div class="alert alert-danger">
<p>We can now see the analogy between the two-factorial ANOVA and the one-factorial ANOVA.</p>
<p>Disentangling a main effect in a two-factorial ANOVA is like disentangling an effect in a one-factorial ANOVA, the only difference being that we use the respective factor’s marginal means instead of cell means.</p>
<p>Disentangling the interaction is also similar to disentangling an effect in a one-factorial ANOVA, the only difference being that we use the mean differences between the two factors instead of cell means.</p>
</div>
<p>We can easily verify that using the contrasts specified above leads to the same results as running the ANOVA, provided that we do not adjust the p-values for multiple comparisons. Let’s quickly recap the ANOVA results from our simulated experiment on job demands and control. Here is the ANOVA output.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: stress
           Effect     df    MSE         F  ges p.value
1         demands 1, 196 455.82 43.92 *** .183   &lt;.001
2         control 1, 196 455.82 20.02 *** .093   &lt;.001
3 demands:control 1, 196 455.82    4.15 * .021    .043
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>Now let’s run a custom contrast analysis on the ANOVA object using <em>emmeans</em> and coapre it to the ANOVA results. Here is the syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># analyse contrasts for main effects and interactions in a 2x2 </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA without correcting for type-I error inflation</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> my_ANOVA, <span class="at">specs =</span> <span class="fu">c</span>(<span class="st">'demands'</span>, <span class="st">'control'</span>),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="fu">list</span>(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">demands =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>),</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">control =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">interaction =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)),</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">adjust =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is the output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 demands control emmean   SE  df lower.CL upper.CL
 low     low      103.6 3.02 196     97.6      110
 high    low      129.7 3.02 196    123.8      136
 low     high      96.2 3.02 196     90.3      102
 high    high     110.1 3.02 196    104.1      116

Confidence level used: 0.95 

$contrasts
 contrast    estimate   SE  df t.ratio p.value
 demands        -40.0 6.04 196  -6.627  &lt;.0001
 control         27.0 6.04 196   4.475  &lt;.0001
 interaction    -12.3 6.04 196  -2.037  0.0430</code></pre>
</div>
</div>
</div>
<p>When we compare the ANOVA results to the results of the custom contrast analysis, we can see that there is only one difference. The ANOVA uses <span class="math inline">\(F\)</span>-statistics whereas the contrasts are analysed using <span class="math inline">\(t\)</span>-statistics. The <span class="math inline">\(F\)</span>-values reported in the ANOVA are the exact squares of the corresponding <span class="math inline">\(t\)</span>-values, and while the <span class="math inline">\(p\)</span>-values of the two main effects are too small to compare them visually between the two analyses, we can see that the <span class="math inline">\(p\)</span>-value of the interaction effect is the same.</p>
<p>What do we do with this knowledge? First of all, we know now what we can state once an interaction in a two-factorial ANOVA is significant: there is a difference of differences. Put differently, we know now that the magnitude of the effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> differ depending on which level of the other factor we look at. This knowledge in mind, we can now start to disentangle the interaction by looking at the <strong>simple effects</strong>.</p>
<p>A <strong>simple effect</strong> is the main effect of one factor when fixing the other factor at a specific level. In a <span class="math inline">\(2 \times 2\)</span>-ANOVA, there are four simple effects:</p>
<ul>
<li>the effect of <span class="math inline">\(A\)</span> when <span class="math inline">\(B\)</span> is fixed at <span class="math inline">\(k=1\)</span></li>
<li>the effect of <span class="math inline">\(A\)</span> when <span class="math inline">\(B\)</span> is fixed at <span class="math inline">\(k=2\)</span></li>
<li>the effect of <span class="math inline">\(B\)</span> when <span class="math inline">\(A\)</span> is fixed at <span class="math inline">\(j=1\)</span></li>
<li>the effect of <span class="math inline">\(B\)</span> when <span class="math inline">\(A\)</span> is fixed at <span class="math inline">\(j=2\)</span></li>
</ul>
<p>In order to understand how a significant interaction effect came about, we need to inspect all four of these simple effects. It may come as no surprise that we will do so using custom contrasts. Here is what the contrast weights would look like:</p>
<table class="table">
<colgroup>
<col style="width: 39%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(j=1\)</span>; <span class="math inline">\(k=1\)</span></th>
<th><span class="math inline">\(j=2\)</span>, <span class="math inline">\(k=1\)</span></th>
<th><span class="math inline">\(j=1\)</span>; <span class="math inline">\(k=2\)</span></th>
<th><span class="math inline">\(j=2\)</span>; <span class="math inline">\(k=2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>simple effect of <span class="math inline">\(A\)</span> for <span class="math inline">\(k=1\)</span></td>
<td>1</td>
<td>-1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>simple effect of <span class="math inline">\(A\)</span> for <span class="math inline">\(k=2\)</span></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>simple effect of <span class="math inline">\(B\)</span> for <span class="math inline">\(j=1\)</span></td>
<td>1</td>
<td>0</td>
<td>-1</td>
<td>0</td>
</tr>
<tr class="even">
<td>simple effect of <span class="math inline">\(B\)</span> for <span class="math inline">\(j=2\)</span></td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>As we an see, simple effects are a subset of the pairwise comparisons. Now let’s have a look at the syntax for the simple effect analysis:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># analysis of the simple effects using custom contrasts</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(<span class="at">object =</span> my_ANOVA, <span class="at">specs =</span> <span class="fu">c</span>(<span class="st">'demands'</span>, <span class="st">'control'</span>),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">contr =</span> <span class="fu">list</span>(</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">demands_for_low_control =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">demands_for_high_control =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">control_for_low_demands =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">control_for_high_demands =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        ))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what the output looks like:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>$emmeans
 demands control emmean   SE  df lower.CL upper.CL
 low     low      103.6 3.02 196     97.6      110
 high    low      129.7 3.02 196    123.8      136
 low     high      96.2 3.02 196     90.3      102
 high    high     110.1 3.02 196    104.1      116

Confidence level used: 0.95 

$contrasts
 contrast                 estimate   SE  df t.ratio p.value
 demands_for_low_control    -26.16 4.27 196  -6.127  &lt;.0001
 demands_for_high_control   -13.86 4.27 196  -3.246  0.0014
 control_for_low_demands      7.36 4.27 196   1.724  0.0863
 control_for_high_demands    19.66 4.27 196   4.604  &lt;.0001</code></pre>
</div>
</div>
</div>
<p>As we can see, all but one of the simple effects are significant. Since the output also shows an estimate of the contrast value for each of the simple effect contrasts, we can now interpret the interaction pattern.</p>
<p><strong>Here is a valid interpretation</strong>: there is an interaction because the effect of job demands on stress is greater when control is low than when it is high.</p>
<p><strong>Another valid interpretation</strong>: there is an interaction because control has an effect on stress when job demands are high, but this effect is weaker when demands are low to the extant that we cannot say based on the data whether it still exists.</p>
<p>As we can see, we can interpret the interaction from the viewpoint of both factors. Which interpretation we need to choose depends on the specific nature of our interaction hypothesis.</p>
</section>
<section id="disentangling-interactions-in-two-factorial-anovas-with-more-than-two-levels" class="level3">
<h3 class="anchored" data-anchor-id="disentangling-interactions-in-two-factorial-anovas-with-more-than-two-levels">Disentangling interactions in two-factorial ANOVAs with more than two levels</h3>
<p>As soon as our design has at least one factor with three or more levels, we need one more step to make sense of the interaction. Let’s consider - for the sake of simplicity - the case of a <span class="math inline">\(2 \times 3\)</span>-ANOVA that yields a significant interaction effect. Now, an analysis of the simple effects is not straightforward because one factor has three levels. While we can easily inspect the simple effect of the two-level factor for all three levels of the other factor, we do not know which pairwise comparison to focus on for the three-level factor.</p>
<p>To narrow things down, we need to remember what exactly an interaction test does: to test for differences between differences. In a <span class="math inline">\(2 \times 3\)</span>-design, this boils down to computing the difference between the two levels of first factor and testing whether this difference (the effect of factor <span class="math inline">\(A\)</span>) differs as a function of the second factor (the one with three levels). Since we now have three levels of factor <span class="math inline">\(B\)</span>, there are three possible pairwise comparisons for the effect of <span class="math inline">\(A\)</span>. The effect of <span class="math inline">\(A\)</span> could differ between the first and second level of <span class="math inline">\(B\)</span>, between its first and third level, or between the second and third level. Of course, it is also possible that two or even all three of these pairwise comparisons point toward differences.</p>
<p>Why is this pairwise comparisons of differences relevant? It allows us to decompose the overall interaction effect into smaller parts that we already know how to handle, namely <span class="math inline">\(2 \times 2\)</span>-interactions. Once we know, which of the three possible <span class="math inline">\(2 \times 2\)</span>-interactions in our <span class="math inline">\(2 \times 3\)</span>-design is significant, we can then proceed by disentangling them in the way described above, namely by inspecting the simple effects.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>